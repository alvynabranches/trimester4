{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization, Dropout, Input, Flatten, Activation, PReLU\n",
    "from tensorflow.keras.losses import MeanSquaredLogarithmicError, MeanAbsolutePercentageError\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop, Nadam\n",
    "from tensorflow.keras.activations import linear, relu\n",
    "from tensorflow.keras.metrics import MeanSquaredLogarithmicError, MeanAbsolutePercentageError, RootMeanSquaredError\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from numpy import sqrt\n",
    "\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number_of_elements</th>\n",
       "      <th>mean_atomic_mass</th>\n",
       "      <th>wtd_mean_atomic_mass</th>\n",
       "      <th>gmean_atomic_mass</th>\n",
       "      <th>wtd_gmean_atomic_mass</th>\n",
       "      <th>entropy_atomic_mass</th>\n",
       "      <th>wtd_entropy_atomic_mass</th>\n",
       "      <th>range_atomic_mass</th>\n",
       "      <th>wtd_range_atomic_mass</th>\n",
       "      <th>std_atomic_mass</th>\n",
       "      <th>...</th>\n",
       "      <th>wtd_mean_Valence</th>\n",
       "      <th>gmean_Valence</th>\n",
       "      <th>wtd_gmean_Valence</th>\n",
       "      <th>entropy_Valence</th>\n",
       "      <th>wtd_entropy_Valence</th>\n",
       "      <th>range_Valence</th>\n",
       "      <th>wtd_range_Valence</th>\n",
       "      <th>std_Valence</th>\n",
       "      <th>wtd_std_Valence</th>\n",
       "      <th>critical_temp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>88.944468</td>\n",
       "      <td>57.862692</td>\n",
       "      <td>66.361592</td>\n",
       "      <td>36.116612</td>\n",
       "      <td>1.181795</td>\n",
       "      <td>1.062396</td>\n",
       "      <td>122.90607</td>\n",
       "      <td>31.794921</td>\n",
       "      <td>51.968828</td>\n",
       "      <td>...</td>\n",
       "      <td>2.257143</td>\n",
       "      <td>2.213364</td>\n",
       "      <td>2.219783</td>\n",
       "      <td>1.368922</td>\n",
       "      <td>1.066221</td>\n",
       "      <td>1</td>\n",
       "      <td>1.085714</td>\n",
       "      <td>0.433013</td>\n",
       "      <td>0.437059</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>92.729214</td>\n",
       "      <td>58.518416</td>\n",
       "      <td>73.132787</td>\n",
       "      <td>36.396602</td>\n",
       "      <td>1.449309</td>\n",
       "      <td>1.057755</td>\n",
       "      <td>122.90607</td>\n",
       "      <td>36.161939</td>\n",
       "      <td>47.094633</td>\n",
       "      <td>...</td>\n",
       "      <td>2.257143</td>\n",
       "      <td>1.888175</td>\n",
       "      <td>2.210679</td>\n",
       "      <td>1.557113</td>\n",
       "      <td>1.047221</td>\n",
       "      <td>2</td>\n",
       "      <td>1.128571</td>\n",
       "      <td>0.632456</td>\n",
       "      <td>0.468606</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>88.944468</td>\n",
       "      <td>57.885242</td>\n",
       "      <td>66.361592</td>\n",
       "      <td>36.122509</td>\n",
       "      <td>1.181795</td>\n",
       "      <td>0.975980</td>\n",
       "      <td>122.90607</td>\n",
       "      <td>35.741099</td>\n",
       "      <td>51.968828</td>\n",
       "      <td>...</td>\n",
       "      <td>2.271429</td>\n",
       "      <td>2.213364</td>\n",
       "      <td>2.232679</td>\n",
       "      <td>1.368922</td>\n",
       "      <td>1.029175</td>\n",
       "      <td>1</td>\n",
       "      <td>1.114286</td>\n",
       "      <td>0.433013</td>\n",
       "      <td>0.444697</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>88.944468</td>\n",
       "      <td>57.873967</td>\n",
       "      <td>66.361592</td>\n",
       "      <td>36.119560</td>\n",
       "      <td>1.181795</td>\n",
       "      <td>1.022291</td>\n",
       "      <td>122.90607</td>\n",
       "      <td>33.768010</td>\n",
       "      <td>51.968828</td>\n",
       "      <td>...</td>\n",
       "      <td>2.264286</td>\n",
       "      <td>2.213364</td>\n",
       "      <td>2.226222</td>\n",
       "      <td>1.368922</td>\n",
       "      <td>1.048834</td>\n",
       "      <td>1</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>0.433013</td>\n",
       "      <td>0.440952</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>88.944468</td>\n",
       "      <td>57.840143</td>\n",
       "      <td>66.361592</td>\n",
       "      <td>36.110716</td>\n",
       "      <td>1.181795</td>\n",
       "      <td>1.129224</td>\n",
       "      <td>122.90607</td>\n",
       "      <td>27.848743</td>\n",
       "      <td>51.968828</td>\n",
       "      <td>...</td>\n",
       "      <td>2.242857</td>\n",
       "      <td>2.213364</td>\n",
       "      <td>2.206963</td>\n",
       "      <td>1.368922</td>\n",
       "      <td>1.096052</td>\n",
       "      <td>1</td>\n",
       "      <td>1.057143</td>\n",
       "      <td>0.433013</td>\n",
       "      <td>0.428809</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>88.944468</td>\n",
       "      <td>57.795044</td>\n",
       "      <td>66.361592</td>\n",
       "      <td>36.098926</td>\n",
       "      <td>1.181795</td>\n",
       "      <td>1.225203</td>\n",
       "      <td>122.90607</td>\n",
       "      <td>20.687458</td>\n",
       "      <td>51.968828</td>\n",
       "      <td>...</td>\n",
       "      <td>2.214286</td>\n",
       "      <td>2.213364</td>\n",
       "      <td>2.181543</td>\n",
       "      <td>1.368922</td>\n",
       "      <td>1.141474</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.433013</td>\n",
       "      <td>0.410326</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>88.944468</td>\n",
       "      <td>57.682296</td>\n",
       "      <td>66.361592</td>\n",
       "      <td>36.069470</td>\n",
       "      <td>1.181795</td>\n",
       "      <td>1.316857</td>\n",
       "      <td>122.90607</td>\n",
       "      <td>10.765639</td>\n",
       "      <td>51.968828</td>\n",
       "      <td>...</td>\n",
       "      <td>2.142857</td>\n",
       "      <td>2.213364</td>\n",
       "      <td>2.119268</td>\n",
       "      <td>1.368922</td>\n",
       "      <td>1.194453</td>\n",
       "      <td>1</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.433013</td>\n",
       "      <td>0.349927</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4</td>\n",
       "      <td>76.517718</td>\n",
       "      <td>57.175142</td>\n",
       "      <td>59.310096</td>\n",
       "      <td>35.891368</td>\n",
       "      <td>1.197273</td>\n",
       "      <td>0.943560</td>\n",
       "      <td>122.90607</td>\n",
       "      <td>36.451199</td>\n",
       "      <td>44.289459</td>\n",
       "      <td>...</td>\n",
       "      <td>2.271429</td>\n",
       "      <td>2.213364</td>\n",
       "      <td>2.232679</td>\n",
       "      <td>1.368922</td>\n",
       "      <td>1.029175</td>\n",
       "      <td>1</td>\n",
       "      <td>1.114286</td>\n",
       "      <td>0.433013</td>\n",
       "      <td>0.444697</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4</td>\n",
       "      <td>76.517718</td>\n",
       "      <td>56.808817</td>\n",
       "      <td>59.310096</td>\n",
       "      <td>35.773432</td>\n",
       "      <td>1.197273</td>\n",
       "      <td>0.981880</td>\n",
       "      <td>122.90607</td>\n",
       "      <td>34.833160</td>\n",
       "      <td>44.289459</td>\n",
       "      <td>...</td>\n",
       "      <td>2.264286</td>\n",
       "      <td>2.213364</td>\n",
       "      <td>2.226222</td>\n",
       "      <td>1.368922</td>\n",
       "      <td>1.048834</td>\n",
       "      <td>1</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>0.433013</td>\n",
       "      <td>0.440952</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4</td>\n",
       "      <td>76.517718</td>\n",
       "      <td>56.442492</td>\n",
       "      <td>59.310096</td>\n",
       "      <td>35.655884</td>\n",
       "      <td>1.197273</td>\n",
       "      <td>1.016495</td>\n",
       "      <td>122.90607</td>\n",
       "      <td>33.215121</td>\n",
       "      <td>44.289459</td>\n",
       "      <td>...</td>\n",
       "      <td>2.257143</td>\n",
       "      <td>2.213364</td>\n",
       "      <td>2.219783</td>\n",
       "      <td>1.368922</td>\n",
       "      <td>1.066221</td>\n",
       "      <td>1</td>\n",
       "      <td>1.085714</td>\n",
       "      <td>0.433013</td>\n",
       "      <td>0.437059</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 82 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   number_of_elements  mean_atomic_mass  wtd_mean_atomic_mass  \\\n",
       "0                   4         88.944468             57.862692   \n",
       "1                   5         92.729214             58.518416   \n",
       "2                   4         88.944468             57.885242   \n",
       "3                   4         88.944468             57.873967   \n",
       "4                   4         88.944468             57.840143   \n",
       "5                   4         88.944468             57.795044   \n",
       "6                   4         88.944468             57.682296   \n",
       "7                   4         76.517718             57.175142   \n",
       "8                   4         76.517718             56.808817   \n",
       "9                   4         76.517718             56.442492   \n",
       "\n",
       "   gmean_atomic_mass  wtd_gmean_atomic_mass  entropy_atomic_mass  \\\n",
       "0          66.361592              36.116612             1.181795   \n",
       "1          73.132787              36.396602             1.449309   \n",
       "2          66.361592              36.122509             1.181795   \n",
       "3          66.361592              36.119560             1.181795   \n",
       "4          66.361592              36.110716             1.181795   \n",
       "5          66.361592              36.098926             1.181795   \n",
       "6          66.361592              36.069470             1.181795   \n",
       "7          59.310096              35.891368             1.197273   \n",
       "8          59.310096              35.773432             1.197273   \n",
       "9          59.310096              35.655884             1.197273   \n",
       "\n",
       "   wtd_entropy_atomic_mass  range_atomic_mass  wtd_range_atomic_mass  \\\n",
       "0                 1.062396          122.90607              31.794921   \n",
       "1                 1.057755          122.90607              36.161939   \n",
       "2                 0.975980          122.90607              35.741099   \n",
       "3                 1.022291          122.90607              33.768010   \n",
       "4                 1.129224          122.90607              27.848743   \n",
       "5                 1.225203          122.90607              20.687458   \n",
       "6                 1.316857          122.90607              10.765639   \n",
       "7                 0.943560          122.90607              36.451199   \n",
       "8                 0.981880          122.90607              34.833160   \n",
       "9                 1.016495          122.90607              33.215121   \n",
       "\n",
       "   std_atomic_mass  ...  wtd_mean_Valence  gmean_Valence  wtd_gmean_Valence  \\\n",
       "0        51.968828  ...          2.257143       2.213364           2.219783   \n",
       "1        47.094633  ...          2.257143       1.888175           2.210679   \n",
       "2        51.968828  ...          2.271429       2.213364           2.232679   \n",
       "3        51.968828  ...          2.264286       2.213364           2.226222   \n",
       "4        51.968828  ...          2.242857       2.213364           2.206963   \n",
       "5        51.968828  ...          2.214286       2.213364           2.181543   \n",
       "6        51.968828  ...          2.142857       2.213364           2.119268   \n",
       "7        44.289459  ...          2.271429       2.213364           2.232679   \n",
       "8        44.289459  ...          2.264286       2.213364           2.226222   \n",
       "9        44.289459  ...          2.257143       2.213364           2.219783   \n",
       "\n",
       "   entropy_Valence  wtd_entropy_Valence  range_Valence  wtd_range_Valence  \\\n",
       "0         1.368922             1.066221              1           1.085714   \n",
       "1         1.557113             1.047221              2           1.128571   \n",
       "2         1.368922             1.029175              1           1.114286   \n",
       "3         1.368922             1.048834              1           1.100000   \n",
       "4         1.368922             1.096052              1           1.057143   \n",
       "5         1.368922             1.141474              1           1.000000   \n",
       "6         1.368922             1.194453              1           0.857143   \n",
       "7         1.368922             1.029175              1           1.114286   \n",
       "8         1.368922             1.048834              1           1.100000   \n",
       "9         1.368922             1.066221              1           1.085714   \n",
       "\n",
       "   std_Valence  wtd_std_Valence  critical_temp  \n",
       "0     0.433013         0.437059           29.0  \n",
       "1     0.632456         0.468606           26.0  \n",
       "2     0.433013         0.444697           19.0  \n",
       "3     0.433013         0.440952           22.0  \n",
       "4     0.433013         0.428809           23.0  \n",
       "5     0.433013         0.410326           23.0  \n",
       "6     0.433013         0.349927           11.0  \n",
       "7     0.433013         0.444697           33.0  \n",
       "8     0.433013         0.440952           36.0  \n",
       "9     0.433013         0.437059           31.0  \n",
       "\n",
       "[10 rows x 82 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00021"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['critical_temp'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "185.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['critical_temp'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3.677780705266081"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['critical_temp'].apply(lambda x: np.log10(x)).min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.2671717284030137"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['critical_temp'].apply(lambda x: np.log10(x)).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['number_of_elements', 'mean_atomic_mass', 'wtd_mean_atomic_mass',\n",
       "       'gmean_atomic_mass', 'wtd_gmean_atomic_mass', 'entropy_atomic_mass',\n",
       "       'wtd_entropy_atomic_mass', 'range_atomic_mass', 'wtd_range_atomic_mass',\n",
       "       'std_atomic_mass', 'wtd_std_atomic_mass', 'mean_fie', 'wtd_mean_fie',\n",
       "       'gmean_fie', 'wtd_gmean_fie', 'entropy_fie', 'wtd_entropy_fie',\n",
       "       'range_fie', 'wtd_range_fie', 'std_fie', 'wtd_std_fie',\n",
       "       'mean_atomic_radius', 'wtd_mean_atomic_radius', 'gmean_atomic_radius',\n",
       "       'wtd_gmean_atomic_radius', 'entropy_atomic_radius',\n",
       "       'wtd_entropy_atomic_radius', 'range_atomic_radius',\n",
       "       'wtd_range_atomic_radius', 'std_atomic_radius', 'wtd_std_atomic_radius',\n",
       "       'mean_Density', 'wtd_mean_Density', 'gmean_Density',\n",
       "       'wtd_gmean_Density', 'entropy_Density', 'wtd_entropy_Density',\n",
       "       'range_Density', 'wtd_range_Density', 'std_Density', 'wtd_std_Density',\n",
       "       'mean_ElectronAffinity', 'wtd_mean_ElectronAffinity',\n",
       "       'gmean_ElectronAffinity', 'wtd_gmean_ElectronAffinity',\n",
       "       'entropy_ElectronAffinity', 'wtd_entropy_ElectronAffinity',\n",
       "       'range_ElectronAffinity', 'wtd_range_ElectronAffinity',\n",
       "       'std_ElectronAffinity', 'wtd_std_ElectronAffinity', 'mean_FusionHeat',\n",
       "       'wtd_mean_FusionHeat', 'gmean_FusionHeat', 'wtd_gmean_FusionHeat',\n",
       "       'entropy_FusionHeat', 'wtd_entropy_FusionHeat', 'range_FusionHeat',\n",
       "       'wtd_range_FusionHeat', 'std_FusionHeat', 'wtd_std_FusionHeat',\n",
       "       'mean_ThermalConductivity', 'wtd_mean_ThermalConductivity',\n",
       "       'gmean_ThermalConductivity', 'wtd_gmean_ThermalConductivity',\n",
       "       'entropy_ThermalConductivity', 'wtd_entropy_ThermalConductivity',\n",
       "       'range_ThermalConductivity', 'wtd_range_ThermalConductivity',\n",
       "       'std_ThermalConductivity', 'wtd_std_ThermalConductivity',\n",
       "       'mean_Valence', 'wtd_mean_Valence', 'gmean_Valence',\n",
       "       'wtd_gmean_Valence', 'entropy_Valence', 'wtd_entropy_Valence',\n",
       "       'range_Valence', 'wtd_range_Valence', 'std_Valence', 'wtd_std_Valence',\n",
       "       'critical_temp'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 21263 entries, 0 to 21262\n",
      "Data columns (total 82 columns):\n",
      " #   Column                           Non-Null Count  Dtype  \n",
      "---  ------                           --------------  -----  \n",
      " 0   number_of_elements               21263 non-null  int64  \n",
      " 1   mean_atomic_mass                 21263 non-null  float64\n",
      " 2   wtd_mean_atomic_mass             21263 non-null  float64\n",
      " 3   gmean_atomic_mass                21263 non-null  float64\n",
      " 4   wtd_gmean_atomic_mass            21263 non-null  float64\n",
      " 5   entropy_atomic_mass              21263 non-null  float64\n",
      " 6   wtd_entropy_atomic_mass          21263 non-null  float64\n",
      " 7   range_atomic_mass                21263 non-null  float64\n",
      " 8   wtd_range_atomic_mass            21263 non-null  float64\n",
      " 9   std_atomic_mass                  21263 non-null  float64\n",
      " 10  wtd_std_atomic_mass              21263 non-null  float64\n",
      " 11  mean_fie                         21263 non-null  float64\n",
      " 12  wtd_mean_fie                     21263 non-null  float64\n",
      " 13  gmean_fie                        21263 non-null  float64\n",
      " 14  wtd_gmean_fie                    21263 non-null  float64\n",
      " 15  entropy_fie                      21263 non-null  float64\n",
      " 16  wtd_entropy_fie                  21263 non-null  float64\n",
      " 17  range_fie                        21263 non-null  float64\n",
      " 18  wtd_range_fie                    21263 non-null  float64\n",
      " 19  std_fie                          21263 non-null  float64\n",
      " 20  wtd_std_fie                      21263 non-null  float64\n",
      " 21  mean_atomic_radius               21263 non-null  float64\n",
      " 22  wtd_mean_atomic_radius           21263 non-null  float64\n",
      " 23  gmean_atomic_radius              21263 non-null  float64\n",
      " 24  wtd_gmean_atomic_radius          21263 non-null  float64\n",
      " 25  entropy_atomic_radius            21263 non-null  float64\n",
      " 26  wtd_entropy_atomic_radius        21263 non-null  float64\n",
      " 27  range_atomic_radius              21263 non-null  int64  \n",
      " 28  wtd_range_atomic_radius          21263 non-null  float64\n",
      " 29  std_atomic_radius                21263 non-null  float64\n",
      " 30  wtd_std_atomic_radius            21263 non-null  float64\n",
      " 31  mean_Density                     21263 non-null  float64\n",
      " 32  wtd_mean_Density                 21263 non-null  float64\n",
      " 33  gmean_Density                    21263 non-null  float64\n",
      " 34  wtd_gmean_Density                21263 non-null  float64\n",
      " 35  entropy_Density                  21263 non-null  float64\n",
      " 36  wtd_entropy_Density              21263 non-null  float64\n",
      " 37  range_Density                    21263 non-null  float64\n",
      " 38  wtd_range_Density                21263 non-null  float64\n",
      " 39  std_Density                      21263 non-null  float64\n",
      " 40  wtd_std_Density                  21263 non-null  float64\n",
      " 41  mean_ElectronAffinity            21263 non-null  float64\n",
      " 42  wtd_mean_ElectronAffinity        21263 non-null  float64\n",
      " 43  gmean_ElectronAffinity           21263 non-null  float64\n",
      " 44  wtd_gmean_ElectronAffinity       21263 non-null  float64\n",
      " 45  entropy_ElectronAffinity         21263 non-null  float64\n",
      " 46  wtd_entropy_ElectronAffinity     21263 non-null  float64\n",
      " 47  range_ElectronAffinity           21263 non-null  float64\n",
      " 48  wtd_range_ElectronAffinity       21263 non-null  float64\n",
      " 49  std_ElectronAffinity             21263 non-null  float64\n",
      " 50  wtd_std_ElectronAffinity         21263 non-null  float64\n",
      " 51  mean_FusionHeat                  21263 non-null  float64\n",
      " 52  wtd_mean_FusionHeat              21263 non-null  float64\n",
      " 53  gmean_FusionHeat                 21263 non-null  float64\n",
      " 54  wtd_gmean_FusionHeat             21263 non-null  float64\n",
      " 55  entropy_FusionHeat               21263 non-null  float64\n",
      " 56  wtd_entropy_FusionHeat           21263 non-null  float64\n",
      " 57  range_FusionHeat                 21263 non-null  float64\n",
      " 58  wtd_range_FusionHeat             21263 non-null  float64\n",
      " 59  std_FusionHeat                   21263 non-null  float64\n",
      " 60  wtd_std_FusionHeat               21263 non-null  float64\n",
      " 61  mean_ThermalConductivity         21263 non-null  float64\n",
      " 62  wtd_mean_ThermalConductivity     21263 non-null  float64\n",
      " 63  gmean_ThermalConductivity        21263 non-null  float64\n",
      " 64  wtd_gmean_ThermalConductivity    21263 non-null  float64\n",
      " 65  entropy_ThermalConductivity      21263 non-null  float64\n",
      " 66  wtd_entropy_ThermalConductivity  21263 non-null  float64\n",
      " 67  range_ThermalConductivity        21263 non-null  float64\n",
      " 68  wtd_range_ThermalConductivity    21263 non-null  float64\n",
      " 69  std_ThermalConductivity          21263 non-null  float64\n",
      " 70  wtd_std_ThermalConductivity      21263 non-null  float64\n",
      " 71  mean_Valence                     21263 non-null  float64\n",
      " 72  wtd_mean_Valence                 21263 non-null  float64\n",
      " 73  gmean_Valence                    21263 non-null  float64\n",
      " 74  wtd_gmean_Valence                21263 non-null  float64\n",
      " 75  entropy_Valence                  21263 non-null  float64\n",
      " 76  wtd_entropy_Valence              21263 non-null  float64\n",
      " 77  range_Valence                    21263 non-null  int64  \n",
      " 78  wtd_range_Valence                21263 non-null  float64\n",
      " 79  std_Valence                      21263 non-null  float64\n",
      " 80  wtd_std_Valence                  21263 non-null  float64\n",
      " 81  critical_temp                    21263 non-null  float64\n",
      "dtypes: float64(79), int64(3)\n",
      "memory usage: 13.3 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "number_of_elements       0\n",
       "mean_atomic_mass         0\n",
       "wtd_mean_atomic_mass     0\n",
       "gmean_atomic_mass        0\n",
       "wtd_gmean_atomic_mass    0\n",
       "                        ..\n",
       "range_Valence            0\n",
       "wtd_range_Valence        0\n",
       "std_Valence              0\n",
       "wtd_std_Valence          0\n",
       "critical_temp            0\n",
       "Length: 82, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:,df.columns != 'critical_temp'].values\n",
    "y = df.iloc[:,df.columns == 'critical_temp'].values\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.15)\n",
    "del X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16265, 81)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"linear_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "first_hidden_layer (Dense)   (None, 81)                6642      \n",
      "_________________________________________________________________\n",
      "second_hidden_layer (Dense)  (None, 162)               13284     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 162)               0         \n",
      "_________________________________________________________________\n",
      "third_hidden_layer (Dense)   (None, 81)                13203     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 81)                0         \n",
      "_________________________________________________________________\n",
      "fourth_hidden_layer (Dense)  (None, 40)                3280      \n",
      "_________________________________________________________________\n",
      "output_layer (Dense)         (None, 1)                 41        \n",
      "=================================================================\n",
      "Total params: 36,450\n",
      "Trainable params: 36,450\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "hidden_activation = 'relu'\n",
    "output_activation = None\n",
    "model = Sequential(name='linear_model')\n",
    "model.add(Input(shape=(81,), name='input_layer'))\n",
    "model.add(Dense(81, activation=hidden_activation, name='first_hidden_layer'))\n",
    "model.add(Dense(162, activation=hidden_activation, name='second_hidden_layer'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(81, activation=hidden_activation, name='third_hidden_layer'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(40, activation=hidden_activation, name='fourth_hidden_layer'))\n",
    "model.add(Dense(1, name='output_layer'))\n",
    "model.compile(loss='mse', optimizer=RMSprop(learning_rate=1e-3), metrics=['msle', 'mae', 'mape', RootMeanSquaredError(name='rmse')])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "509/509 [==============================] - 3s 6ms/step - loss: 6976.8257 - msle: 2.5376 - mae: 40.9991 - mape: 10016.1562 - rmse: 83.5274 - val_loss: 466.9200 - val_msle: 0.8000 - val_mae: 16.1638 - val_mape: 414.3404 - val_rmse: 21.6083\n",
      "Epoch 2/100\n",
      "509/509 [==============================] - 2s 3ms/step - loss: 534.8356 - msle: 0.8490 - mae: 16.6125 - mape: 1621.3136 - rmse: 23.1265 - val_loss: 446.1453 - val_msle: 0.6310 - val_mae: 14.7341 - val_mape: 541.8490 - val_rmse: 21.1222\n",
      "Epoch 3/100\n",
      "509/509 [==============================] - 2s 4ms/step - loss: 436.1039 - msle: 0.6695 - mae: 14.6030 - mape: 1732.2390 - rmse: 20.8831 - val_loss: 479.5086 - val_msle: 0.5046 - val_mae: 14.8978 - val_mape: 370.7248 - val_rmse: 21.8977\n",
      "Epoch 4/100\n",
      "509/509 [==============================] - 3s 5ms/step - loss: 395.2169 - msle: 0.5746 - mae: 13.6850 - mape: 1457.7228 - rmse: 19.8801 - val_loss: 339.9217 - val_msle: 0.5401 - val_mae: 12.8473 - val_mape: 325.3253 - val_rmse: 18.4370\n",
      "Epoch 5/100\n",
      "509/509 [==============================] - 2s 3ms/step - loss: 382.0656 - msle: 0.5505 - mae: 13.3246 - mape: 934.1583 - rmse: 19.5465 - val_loss: 304.1328 - val_msle: 0.5102 - val_mae: 12.2273 - val_mape: 314.0524 - val_rmse: 17.4394\n",
      "Epoch 6/100\n",
      "509/509 [==============================] - 3s 5ms/step - loss: 359.5945 - msle: 0.5221 - mae: 12.8603 - mape: 1343.6799 - rmse: 18.9630 - val_loss: 428.2180 - val_msle: 0.4678 - val_mae: 14.2236 - val_mape: 246.0430 - val_rmse: 20.6934\n",
      "Epoch 7/100\n",
      "509/509 [==============================] - 2s 4ms/step - loss: 349.3590 - msle: 0.4923 - mae: 12.6183 - mape: 953.4283 - rmse: 18.6911 - val_loss: 606.2507 - val_msle: 0.5268 - val_mae: 16.3954 - val_mape: 379.2333 - val_rmse: 24.6222\n",
      "Epoch 8/100\n",
      "509/509 [==============================] - 3s 5ms/step - loss: 342.6366 - msle: 0.4751 - mae: 12.4109 - mape: 1140.9279 - rmse: 18.5104 - val_loss: 403.2309 - val_msle: 0.4241 - val_mae: 13.8935 - val_mape: 292.4158 - val_rmse: 20.0806\n",
      "Epoch 9/100\n",
      "509/509 [==============================] - 2s 4ms/step - loss: 332.1144 - msle: 0.4587 - mae: 12.2108 - mape: 996.4235 - rmse: 18.2240 - val_loss: 556.4172 - val_msle: 0.4951 - val_mae: 15.9422 - val_mape: 300.1098 - val_rmse: 23.5885\n",
      "Epoch 10/100\n",
      "509/509 [==============================] - 2s 4ms/step - loss: 330.8922 - msle: 0.4529 - mae: 12.2475 - mape: 1043.8660 - rmse: 18.1904 - val_loss: 562.0694 - val_msle: 0.4858 - val_mae: 16.0406 - val_mape: 304.2015 - val_rmse: 23.7080\n",
      "Epoch 11/100\n",
      "509/509 [==============================] - 2s 5ms/step - loss: 325.3429 - msle: 0.4457 - mae: 12.0723 - mape: 1178.9467 - rmse: 18.0373 - val_loss: 320.7199 - val_msle: 0.4618 - val_mae: 11.9888 - val_mape: 315.8746 - val_rmse: 17.9087\n",
      "Epoch 12/100\n",
      "509/509 [==============================] - 2s 4ms/step - loss: 316.0458 - msle: 0.4321 - mae: 11.8796 - mape: 967.5004 - rmse: 17.7777 - val_loss: 751.4599 - val_msle: 0.5648 - val_mae: 18.3022 - val_mape: 250.2364 - val_rmse: 27.4128\n",
      "Epoch 13/100\n",
      "509/509 [==============================] - 2s 5ms/step - loss: 310.1363 - msle: 0.4251 - mae: 11.7640 - mape: 874.8031 - rmse: 17.6107 - val_loss: 383.0190 - val_msle: 0.4049 - val_mae: 13.4422 - val_mape: 281.9823 - val_rmse: 19.5709\n",
      "Epoch 14/100\n",
      "509/509 [==============================] - 2s 4ms/step - loss: 310.6626 - msle: 0.4212 - mae: 11.7552 - mape: 1008.8983 - rmse: 17.6256 - val_loss: 390.3286 - val_msle: 0.4290 - val_mae: 13.7111 - val_mape: 342.3763 - val_rmse: 19.7567\n",
      "Epoch 15/100\n",
      "509/509 [==============================] - 2s 4ms/step - loss: 304.3214 - msle: 0.4160 - mae: 11.6396 - mape: 1193.6997 - rmse: 17.4448 - val_loss: 419.1036 - val_msle: 0.4145 - val_mae: 13.9825 - val_mape: 303.0987 - val_rmse: 20.4720\n",
      "Epoch 16/100\n",
      "509/509 [==============================] - 2s 4ms/step - loss: 300.5263 - msle: 0.4154 - mae: 11.5458 - mape: 1047.6005 - rmse: 17.3357 - val_loss: 361.9330 - val_msle: 0.3906 - val_mae: 12.9452 - val_mape: 315.8944 - val_rmse: 19.0245\n",
      "Epoch 17/100\n",
      "509/509 [==============================] - 3s 5ms/step - loss: 298.3693 - msle: 0.4074 - mae: 11.4757 - mape: 1012.8732 - rmse: 17.2734 - val_loss: 294.2108 - val_msle: 0.4180 - val_mae: 11.6514 - val_mape: 308.0751 - val_rmse: 17.1526\n",
      "Epoch 18/100\n",
      "509/509 [==============================] - 2s 4ms/step - loss: 290.8981 - msle: 0.4013 - mae: 11.3627 - mape: 986.4156 - rmse: 17.0557 - val_loss: 761.7698 - val_msle: 0.5551 - val_mae: 18.4432 - val_mape: 284.9020 - val_rmse: 27.6002\n",
      "Epoch 19/100\n",
      "509/509 [==============================] - 2s 5ms/step - loss: 291.6730 - msle: 0.4040 - mae: 11.4020 - mape: 1049.6113 - rmse: 17.0784 - val_loss: 287.4901 - val_msle: 0.4032 - val_mae: 11.7209 - val_mape: 322.4224 - val_rmse: 16.9555\n",
      "Epoch 20/100\n",
      "509/509 [==============================] - 2s 5ms/step - loss: 294.9136 - msle: 0.4023 - mae: 11.3926 - mape: 1076.9276 - rmse: 17.1730 - val_loss: 332.7697 - val_msle: 0.4715 - val_mae: 12.2866 - val_mape: 409.0621 - val_rmse: 18.2420\n",
      "Epoch 21/100\n",
      "509/509 [==============================] - 2s 4ms/step - loss: 287.6751 - msle: 0.3942 - mae: 11.2624 - mape: 1061.8539 - rmse: 16.9610 - val_loss: 570.5732 - val_msle: 0.4587 - val_mae: 15.9364 - val_mape: 294.7025 - val_rmse: 23.8867\n",
      "Epoch 22/100\n",
      "509/509 [==============================] - 2s 5ms/step - loss: 286.1645 - msle: 0.3940 - mae: 11.2181 - mape: 999.3243 - rmse: 16.9164 - val_loss: 485.1034 - val_msle: 0.4352 - val_mae: 14.9085 - val_mape: 316.7215 - val_rmse: 22.0251\n",
      "Epoch 23/100\n",
      "509/509 [==============================] - 2s 4ms/step - loss: 286.9721 - msle: 0.3937 - mae: 11.2223 - mape: 1147.4553 - rmse: 16.9403 - val_loss: 272.9804 - val_msle: 0.4194 - val_mae: 11.3510 - val_mape: 336.6989 - val_rmse: 16.5221\n",
      "Epoch 24/100\n",
      "509/509 [==============================] - 2s 5ms/step - loss: 281.8720 - msle: 0.3913 - mae: 11.1526 - mape: 995.2108 - rmse: 16.7890 - val_loss: 295.8070 - val_msle: 0.3802 - val_mae: 11.9223 - val_mape: 321.9677 - val_rmse: 17.1990\n",
      "Epoch 25/100\n",
      "509/509 [==============================] - 2s 4ms/step - loss: 282.8901 - msle: 0.3922 - mae: 11.1650 - mape: 1334.4229 - rmse: 16.8193 - val_loss: 262.8817 - val_msle: 0.4110 - val_mae: 11.2098 - val_mape: 359.9223 - val_rmse: 16.2136\n",
      "Epoch 26/100\n",
      "509/509 [==============================] - 3s 5ms/step - loss: 281.0579 - msle: 0.3902 - mae: 11.1100 - mape: 1027.6288 - rmse: 16.7648 - val_loss: 307.9205 - val_msle: 0.3769 - val_mae: 12.1143 - val_mape: 314.1748 - val_rmse: 17.5477\n",
      "Epoch 27/100\n",
      "509/509 [==============================] - 2s 4ms/step - loss: 280.0359 - msle: 0.3855 - mae: 11.0937 - mape: 980.6979 - rmse: 16.7343 - val_loss: 301.0380 - val_msle: 0.3948 - val_mae: 11.9949 - val_mape: 327.1367 - val_rmse: 17.3504\n",
      "Epoch 28/100\n",
      "509/509 [==============================] - 2s 4ms/step - loss: 274.9297 - msle: 0.3864 - mae: 11.0229 - mape: 1011.5582 - rmse: 16.5810 - val_loss: 295.9371 - val_msle: 0.4332 - val_mae: 10.9572 - val_mape: 360.1278 - val_rmse: 17.2028\n",
      "Epoch 29/100\n",
      "509/509 [==============================] - 2s 4ms/step - loss: 274.3091 - msle: 0.3804 - mae: 10.9022 - mape: 1106.3699 - rmse: 16.5623 - val_loss: 443.6467 - val_msle: 0.3914 - val_mae: 14.1717 - val_mape: 284.1711 - val_rmse: 21.0629\n",
      "Epoch 30/100\n",
      "509/509 [==============================] - 2s 4ms/step - loss: 271.9256 - msle: 0.3783 - mae: 10.9640 - mape: 1035.7201 - rmse: 16.4902 - val_loss: 434.4746 - val_msle: 0.3933 - val_mae: 14.1810 - val_mape: 271.4744 - val_rmse: 20.8441\n",
      "Epoch 31/100\n",
      "509/509 [==============================] - 3s 5ms/step - loss: 273.6037 - msle: 0.3791 - mae: 10.9426 - mape: 1056.7925 - rmse: 16.5410 - val_loss: 265.1433 - val_msle: 0.3785 - val_mae: 11.2011 - val_mape: 315.6283 - val_rmse: 16.2832\n",
      "Epoch 32/100\n",
      "509/509 [==============================] - 2s 4ms/step - loss: 271.0927 - msle: 0.3797 - mae: 10.9168 - mape: 1119.6340 - rmse: 16.4649 - val_loss: 319.1107 - val_msle: 0.3699 - val_mae: 12.2091 - val_mape: 298.7239 - val_rmse: 17.8637\n",
      "Epoch 33/100\n",
      "509/509 [==============================] - 3s 5ms/step - loss: 269.0785 - msle: 0.3736 - mae: 10.8417 - mape: 1159.9526 - rmse: 16.4036 - val_loss: 257.5289 - val_msle: 0.3509 - val_mae: 10.9933 - val_mape: 290.8163 - val_rmse: 16.0477\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/100\n",
      "509/509 [==============================] - 2s 4ms/step - loss: 264.8836 - msle: 0.3741 - mae: 10.7876 - mape: 1069.8356 - rmse: 16.2752 - val_loss: 267.6298 - val_msle: 0.3868 - val_mae: 11.2957 - val_mape: 324.2413 - val_rmse: 16.3594\n",
      "Epoch 35/100\n",
      "509/509 [==============================] - 3s 5ms/step - loss: 267.9315 - msle: 0.3735 - mae: 10.8275 - mape: 969.8117 - rmse: 16.3686 - val_loss: 284.1346 - val_msle: 0.3687 - val_mae: 11.7226 - val_mape: 289.1176 - val_rmse: 16.8563\n",
      "Epoch 36/100\n",
      "509/509 [==============================] - 2s 4ms/step - loss: 264.1434 - msle: 0.3721 - mae: 10.7517 - mape: 965.8417 - rmse: 16.2525 - val_loss: 610.4911 - val_msle: 0.4771 - val_mae: 16.1269 - val_mape: 264.2707 - val_rmse: 24.7081\n",
      "Epoch 37/100\n",
      "509/509 [==============================] - 3s 5ms/step - loss: 267.2259 - msle: 0.3684 - mae: 10.8042 - mape: 1005.7065 - rmse: 16.3470 - val_loss: 266.4095 - val_msle: 0.4010 - val_mae: 11.1810 - val_mape: 332.9388 - val_rmse: 16.3221\n",
      "Epoch 38/100\n",
      "509/509 [==============================] - 2s 4ms/step - loss: 264.6276 - msle: 0.3689 - mae: 10.7523 - mape: 1090.7177 - rmse: 16.2674 - val_loss: 468.3605 - val_msle: 0.4003 - val_mae: 14.7360 - val_mape: 271.5914 - val_rmse: 21.6416\n",
      "Epoch 39/100\n",
      "509/509 [==============================] - 2s 5ms/step - loss: 266.6228 - msle: 0.3677 - mae: 10.7851 - mape: 1212.1967 - rmse: 16.3286 - val_loss: 290.8665 - val_msle: 0.3653 - val_mae: 11.7796 - val_mape: 277.6696 - val_rmse: 17.0548\n",
      "Epoch 40/100\n",
      "509/509 [==============================] - 2s 4ms/step - loss: 262.3545 - msle: 0.3692 - mae: 10.6853 - mape: 1108.2933 - rmse: 16.1974 - val_loss: 296.7809 - val_msle: 0.3828 - val_mae: 11.8197 - val_mape: 319.7826 - val_rmse: 17.2273\n",
      "Epoch 41/100\n",
      "509/509 [==============================] - 2s 5ms/step - loss: 265.7022 - msle: 0.3714 - mae: 10.7958 - mape: 1040.3591 - rmse: 16.3004 - val_loss: 390.4142 - val_msle: 0.3774 - val_mae: 13.5420 - val_mape: 312.8348 - val_rmse: 19.7589\n",
      "Epoch 42/100\n",
      "509/509 [==============================] - 2s 5ms/step - loss: 264.2838 - msle: 0.3695 - mae: 10.7501 - mape: 1141.4824 - rmse: 16.2568 - val_loss: 376.1967 - val_msle: 0.3706 - val_mae: 13.1727 - val_mape: 302.4648 - val_rmse: 19.3958\n",
      "Epoch 43/100\n",
      "509/509 [==============================] - 2s 5ms/step - loss: 260.8287 - msle: 0.3636 - mae: 10.6811 - mape: 864.8011 - rmse: 16.1502 - val_loss: 277.0712 - val_msle: 0.3807 - val_mae: 11.5190 - val_mape: 316.8814 - val_rmse: 16.6455\n",
      "Epoch 44/100\n",
      "509/509 [==============================] - 3s 5ms/step - loss: 263.9779 - msle: 0.3670 - mae: 10.7356 - mape: 1152.3374 - rmse: 16.2474 - val_loss: 304.1758 - val_msle: 0.3605 - val_mae: 12.0030 - val_mape: 294.5924 - val_rmse: 17.4406\n",
      "Epoch 45/100\n",
      "509/509 [==============================] - 2s 4ms/step - loss: 259.7028 - msle: 0.3685 - mae: 10.6401 - mape: 950.8482 - rmse: 16.1153 - val_loss: 259.9763 - val_msle: 0.3709 - val_mae: 11.0559 - val_mape: 318.8928 - val_rmse: 16.1238\n",
      "Epoch 46/100\n",
      "509/509 [==============================] - 3s 5ms/step - loss: 258.4312 - msle: 0.3668 - mae: 10.6402 - mape: 1054.5754 - rmse: 16.0758 - val_loss: 509.3520 - val_msle: 0.4100 - val_mae: 15.2604 - val_mape: 247.4780 - val_rmse: 22.5688\n",
      "Epoch 47/100\n",
      "509/509 [==============================] - 2s 4ms/step - loss: 259.4388 - msle: 0.3648 - mae: 10.6049 - mape: 1069.7556 - rmse: 16.1071 - val_loss: 255.8296 - val_msle: 0.4135 - val_mae: 11.0772 - val_mape: 394.4815 - val_rmse: 15.9947\n",
      "Epoch 48/100\n",
      "509/509 [==============================] - 3s 5ms/step - loss: 259.3065 - msle: 0.3670 - mae: 10.6598 - mape: 993.7085 - rmse: 16.1030 - val_loss: 677.7944 - val_msle: 0.4770 - val_mae: 17.1756 - val_mape: 281.5515 - val_rmse: 26.0345\n",
      "Epoch 49/100\n",
      "509/509 [==============================] - 2s 4ms/step - loss: 259.9461 - msle: 0.3678 - mae: 10.6437 - mape: 1038.3191 - rmse: 16.1228 - val_loss: 271.1158 - val_msle: 0.4084 - val_mae: 11.0375 - val_mape: 333.8846 - val_rmse: 16.4656\n",
      "Epoch 50/100\n",
      "509/509 [==============================] - 2s 5ms/step - loss: 256.8396 - msle: 0.3608 - mae: 10.5883 - mape: 941.0934 - rmse: 16.0262 - val_loss: 266.7451 - val_msle: 0.3927 - val_mae: 11.2603 - val_mape: 342.1823 - val_rmse: 16.3323\n",
      "Epoch 51/100\n",
      "509/509 [==============================] - 2s 4ms/step - loss: 257.0014 - msle: 0.3554 - mae: 10.5366 - mape: 1050.3186 - rmse: 16.0313 - val_loss: 295.2870 - val_msle: 0.3726 - val_mae: 11.8528 - val_mape: 292.3416 - val_rmse: 17.1839\n",
      "Epoch 52/100\n",
      "509/509 [==============================] - 1s 3ms/step - loss: 256.3369 - msle: 0.3666 - mae: 10.5589 - mape: 993.6251 - rmse: 16.0105 - val_loss: 260.1428 - val_msle: 0.3785 - val_mae: 10.4850 - val_mape: 325.2255 - val_rmse: 16.1289\n",
      "Epoch 53/100\n",
      "509/509 [==============================] - 1s 3ms/step - loss: 254.7704 - msle: 0.3576 - mae: 10.5126 - mape: 1022.6821 - rmse: 15.9615 - val_loss: 449.8908 - val_msle: 0.4153 - val_mae: 14.6092 - val_mape: 276.7797 - val_rmse: 21.2106\n",
      "Epoch 54/100\n",
      "509/509 [==============================] - 1s 3ms/step - loss: 256.3206 - msle: 0.3616 - mae: 10.5291 - mape: 1120.6610 - rmse: 16.0100 - val_loss: 397.1635 - val_msle: 0.3781 - val_mae: 13.6295 - val_mape: 290.1961 - val_rmse: 19.9290\n",
      "Epoch 55/100\n",
      "509/509 [==============================] - 1s 3ms/step - loss: 256.5065 - msle: 0.3606 - mae: 10.5615 - mape: 1021.4473 - rmse: 16.0158 - val_loss: 318.0003 - val_msle: 0.3611 - val_mae: 12.2277 - val_mape: 301.3677 - val_rmse: 17.8326\n",
      "Epoch 56/100\n",
      "509/509 [==============================] - 2s 4ms/step - loss: 253.4461 - msle: 0.3621 - mae: 10.4805 - mape: 1039.6205 - rmse: 15.9200 - val_loss: 288.8267 - val_msle: 0.3478 - val_mae: 11.6772 - val_mape: 278.9103 - val_rmse: 16.9949\n",
      "Epoch 57/100\n",
      "509/509 [==============================] - 2s 4ms/step - loss: 254.8808 - msle: 0.3628 - mae: 10.5655 - mape: 1121.2670 - rmse: 15.9650 - val_loss: 269.7190 - val_msle: 0.3643 - val_mae: 11.3540 - val_mape: 322.6693 - val_rmse: 16.4231\n",
      "Epoch 58/100\n",
      "509/509 [==============================] - 3s 5ms/step - loss: 250.0480 - msle: 0.3570 - mae: 10.4305 - mape: 1019.9704 - rmse: 15.8129 - val_loss: 792.4448 - val_msle: 0.5608 - val_mae: 18.6359 - val_mape: 283.3263 - val_rmse: 28.1504\n",
      "Epoch 59/100\n",
      "509/509 [==============================] - 2s 4ms/step - loss: 253.2708 - msle: 0.3582 - mae: 10.4725 - mape: 995.5225 - rmse: 15.9145 - val_loss: 247.6278 - val_msle: 0.3811 - val_mae: 10.7644 - val_mape: 340.6945 - val_rmse: 15.7362\n",
      "Epoch 60/100\n",
      "509/509 [==============================] - 2s 4ms/step - loss: 253.8533 - msle: 0.3620 - mae: 10.5283 - mape: 1037.9054 - rmse: 15.9328 - val_loss: 281.4054 - val_msle: 0.3557 - val_mae: 11.5601 - val_mape: 300.8899 - val_rmse: 16.7751\n",
      "Epoch 61/100\n",
      "509/509 [==============================] - 2s 5ms/step - loss: 251.7332 - msle: 0.3566 - mae: 10.5154 - mape: 1134.2668 - rmse: 15.8661 - val_loss: 373.6284 - val_msle: 0.3687 - val_mae: 13.1022 - val_mape: 292.5222 - val_rmse: 19.3295\n",
      "Epoch 62/100\n",
      "509/509 [==============================] - 2s 4ms/step - loss: 253.4506 - msle: 0.3585 - mae: 10.4820 - mape: 996.8386 - rmse: 15.9201 - val_loss: 260.7557 - val_msle: 0.3569 - val_mae: 10.9899 - val_mape: 302.6343 - val_rmse: 16.1479\n",
      "Epoch 63/100\n",
      "509/509 [==============================] - 3s 5ms/step - loss: 250.1293 - msle: 0.3555 - mae: 10.4489 - mape: 1087.8735 - rmse: 15.8155 - val_loss: 267.5689 - val_msle: 0.3623 - val_mae: 11.2214 - val_mape: 310.9198 - val_rmse: 16.3575\n",
      "Epoch 64/100\n",
      "509/509 [==============================] - 2s 3ms/step - loss: 253.0823 - msle: 0.3591 - mae: 10.4762 - mape: 1264.7787 - rmse: 15.9086 - val_loss: 357.8104 - val_msle: 0.3622 - val_mae: 12.8785 - val_mape: 296.9467 - val_rmse: 18.9159\n",
      "Epoch 65/100\n",
      "509/509 [==============================] - 2s 5ms/step - loss: 252.0358 - msle: 0.3546 - mae: 10.4507 - mape: 938.4763 - rmse: 15.8756 - val_loss: 260.3706 - val_msle: 0.3526 - val_mae: 11.1247 - val_mape: 312.9095 - val_rmse: 16.1360\n",
      "Epoch 66/100\n",
      "509/509 [==============================] - 2s 4ms/step - loss: 250.4097 - msle: 0.3535 - mae: 10.3824 - mape: 1141.2764 - rmse: 15.8243 - val_loss: 331.1862 - val_msle: 0.3503 - val_mae: 12.4814 - val_mape: 269.9643 - val_rmse: 18.1985\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67/100\n",
      "509/509 [==============================] - 2s 4ms/step - loss: 250.5587 - msle: 0.3624 - mae: 10.4302 - mape: 1101.2600 - rmse: 15.8290 - val_loss: 318.5468 - val_msle: 0.3530 - val_mae: 12.2201 - val_mape: 292.6193 - val_rmse: 17.8479\n",
      "Epoch 68/100\n",
      "509/509 [==============================] - 2s 5ms/step - loss: 252.0531 - msle: 0.3589 - mae: 10.4389 - mape: 1069.3148 - rmse: 15.8762 - val_loss: 399.8172 - val_msle: 0.3764 - val_mae: 13.6522 - val_mape: 276.9178 - val_rmse: 19.9954\n",
      "Epoch 69/100\n",
      "509/509 [==============================] - 2s 4ms/step - loss: 251.9237 - msle: 0.3532 - mae: 10.4042 - mape: 1057.3114 - rmse: 15.8721 - val_loss: 538.0956 - val_msle: 0.4330 - val_mae: 15.6645 - val_mape: 278.2735 - val_rmse: 23.1969\n",
      "Epoch 70/100\n",
      "509/509 [==============================] - 3s 5ms/step - loss: 250.9852 - msle: 0.3559 - mae: 10.4298 - mape: 1130.9565 - rmse: 15.8425 - val_loss: 270.4688 - val_msle: 0.3705 - val_mae: 11.2254 - val_mape: 314.3559 - val_rmse: 16.4459\n",
      "Epoch 71/100\n",
      "509/509 [==============================] - 2s 4ms/step - loss: 249.3208 - msle: 0.3589 - mae: 10.4093 - mape: 1119.9733 - rmse: 15.7899 - val_loss: 416.6432 - val_msle: 0.3771 - val_mae: 13.7932 - val_mape: 293.6950 - val_rmse: 20.4118\n",
      "Epoch 72/100\n",
      "509/509 [==============================] - 3s 5ms/step - loss: 246.7582 - msle: 0.3565 - mae: 10.3802 - mape: 1120.2184 - rmse: 15.7085 - val_loss: 276.3083 - val_msle: 0.3517 - val_mae: 11.3977 - val_mape: 299.4766 - val_rmse: 16.6225\n",
      "Epoch 73/100\n",
      "509/509 [==============================] - 2s 4ms/step - loss: 245.4326 - msle: 0.3545 - mae: 10.3049 - mape: 1207.2982 - rmse: 15.6663 - val_loss: 310.2299 - val_msle: 0.3622 - val_mae: 12.0683 - val_mape: 314.4613 - val_rmse: 17.6133\n",
      "Epoch 74/100\n",
      "509/509 [==============================] - 3s 5ms/step - loss: 244.3949 - msle: 0.3542 - mae: 10.3158 - mape: 1173.4309 - rmse: 15.6331 - val_loss: 243.5228 - val_msle: 0.3700 - val_mae: 10.7038 - val_mape: 330.7223 - val_rmse: 15.6052\n",
      "Epoch 75/100\n",
      "509/509 [==============================] - 2s 4ms/step - loss: 244.7976 - msle: 0.3538 - mae: 10.3386 - mape: 1117.7974 - rmse: 15.6460 - val_loss: 474.9069 - val_msle: 0.4022 - val_mae: 14.6246 - val_mape: 299.9206 - val_rmse: 21.7924\n",
      "Epoch 76/100\n",
      "509/509 [==============================] - 2s 5ms/step - loss: 244.7244 - msle: 0.3490 - mae: 10.2806 - mape: 1111.0377 - rmse: 15.6437 - val_loss: 328.2414 - val_msle: 0.3610 - val_mae: 12.3609 - val_mape: 312.9889 - val_rmse: 18.1174\n",
      "Epoch 77/100\n",
      "509/509 [==============================] - 2s 4ms/step - loss: 242.9914 - msle: 0.3522 - mae: 10.2906 - mape: 1116.6613 - rmse: 15.5882 - val_loss: 311.6363 - val_msle: 0.3576 - val_mae: 12.0628 - val_mape: 291.8920 - val_rmse: 17.6532\n",
      "Epoch 78/100\n",
      "509/509 [==============================] - 2s 5ms/step - loss: 248.0942 - msle: 0.3538 - mae: 10.3667 - mape: 1002.1716 - rmse: 15.7510 - val_loss: 463.1800 - val_msle: 0.4185 - val_mae: 14.4710 - val_mape: 320.0703 - val_rmse: 21.5216\n",
      "Epoch 79/100\n",
      "509/509 [==============================] - 2s 5ms/step - loss: 244.5693 - msle: 0.3528 - mae: 10.3148 - mape: 1157.6278 - rmse: 15.6387 - val_loss: 345.6982 - val_msle: 0.3558 - val_mae: 12.6828 - val_mape: 298.7780 - val_rmse: 18.5930\n",
      "Epoch 80/100\n",
      "509/509 [==============================] - 2s 5ms/step - loss: 246.0633 - msle: 0.3489 - mae: 10.2876 - mape: 1094.8718 - rmse: 15.6864 - val_loss: 235.7204 - val_msle: 0.3473 - val_mae: 10.4797 - val_mape: 243.9269 - val_rmse: 15.3532\n",
      "Epoch 81/100\n",
      "509/509 [==============================] - 1s 3ms/step - loss: 243.2090 - msle: 0.3475 - mae: 10.2061 - mape: 1124.9999 - rmse: 15.5952 - val_loss: 289.9733 - val_msle: 0.3468 - val_mae: 11.6233 - val_mape: 274.9844 - val_rmse: 17.0286\n",
      "Epoch 82/100\n",
      "509/509 [==============================] - 1s 3ms/step - loss: 244.2626 - msle: 0.3520 - mae: 10.2720 - mape: 1112.4159 - rmse: 15.6289 - val_loss: 266.0035 - val_msle: 0.3450 - val_mae: 11.0691 - val_mape: 262.1349 - val_rmse: 16.3096\n",
      "Epoch 83/100\n",
      "509/509 [==============================] - 1s 3ms/step - loss: 242.4669 - msle: 0.3504 - mae: 10.2444 - mape: 1045.1815 - rmse: 15.5713 - val_loss: 311.5208 - val_msle: 0.3464 - val_mae: 11.9048 - val_mape: 262.1584 - val_rmse: 17.6500\n",
      "Epoch 84/100\n",
      "509/509 [==============================] - 1s 3ms/step - loss: 241.0604 - msle: 0.3470 - mae: 10.2375 - mape: 970.8758 - rmse: 15.5261 - val_loss: 231.7979 - val_msle: 0.3552 - val_mae: 10.0953 - val_mape: 263.6858 - val_rmse: 15.2249\n",
      "Epoch 85/100\n",
      "509/509 [==============================] - 1s 3ms/step - loss: 240.4177 - msle: 0.3477 - mae: 10.1592 - mape: 1021.6293 - rmse: 15.5054 - val_loss: 450.3900 - val_msle: 0.3864 - val_mae: 14.3438 - val_mape: 286.5396 - val_rmse: 21.2224\n",
      "Epoch 86/100\n",
      "509/509 [==============================] - 1s 3ms/step - loss: 237.1284 - msle: 0.3423 - mae: 10.0931 - mape: 1083.9922 - rmse: 15.3990 - val_loss: 274.3641 - val_msle: 0.3549 - val_mae: 11.4030 - val_mape: 303.3625 - val_rmse: 16.5639\n",
      "Epoch 87/100\n",
      "509/509 [==============================] - 1s 3ms/step - loss: 242.6819 - msle: 0.3426 - mae: 10.2149 - mape: 1011.3402 - rmse: 15.5782 - val_loss: 252.1070 - val_msle: 0.3563 - val_mae: 10.8900 - val_mape: 310.3122 - val_rmse: 15.8779\n",
      "Epoch 88/100\n",
      "509/509 [==============================] - 1s 3ms/step - loss: 242.0517 - msle: 0.3466 - mae: 10.2101 - mape: 1112.5696 - rmse: 15.5580 - val_loss: 328.5183 - val_msle: 0.3692 - val_mae: 12.4136 - val_mape: 269.9055 - val_rmse: 18.1251\n",
      "Epoch 89/100\n",
      "509/509 [==============================] - 1s 3ms/step - loss: 237.3026 - msle: 0.3417 - mae: 10.1133 - mape: 968.1901 - rmse: 15.4046 - val_loss: 324.9772 - val_msle: 0.3752 - val_mae: 12.3275 - val_mape: 313.2997 - val_rmse: 18.0271\n",
      "Epoch 90/100\n",
      "509/509 [==============================] - 1s 3ms/step - loss: 240.2247 - msle: 0.3444 - mae: 10.1657 - mape: 1087.8716 - rmse: 15.4992 - val_loss: 309.2422 - val_msle: 0.3225 - val_mae: 11.9131 - val_mape: 251.8845 - val_rmse: 17.5853\n",
      "Epoch 91/100\n",
      "509/509 [==============================] - 1s 3ms/step - loss: 239.7075 - msle: 0.3418 - mae: 10.1500 - mape: 1100.2947 - rmse: 15.4825 - val_loss: 253.5846 - val_msle: 0.3429 - val_mae: 10.8520 - val_mape: 290.3169 - val_rmse: 15.9243\n",
      "Epoch 92/100\n",
      "509/509 [==============================] - 1s 3ms/step - loss: 241.7465 - msle: 0.3419 - mae: 10.1809 - mape: 1189.3326 - rmse: 15.5482 - val_loss: 285.3747 - val_msle: 0.3580 - val_mae: 11.5641 - val_mape: 277.5291 - val_rmse: 16.8930\n",
      "Epoch 93/100\n",
      "509/509 [==============================] - 2s 4ms/step - loss: 240.6377 - msle: 0.3407 - mae: 10.1943 - mape: 1078.4761 - rmse: 15.5125 - val_loss: 232.1485 - val_msle: 0.3386 - val_mae: 10.3337 - val_mape: 240.6510 - val_rmse: 15.2364\n",
      "Epoch 94/100\n",
      "509/509 [==============================] - 1s 3ms/step - loss: 240.0694 - msle: 0.3382 - mae: 10.1246 - mape: 1080.8809 - rmse: 15.4942 - val_loss: 312.7509 - val_msle: 0.3378 - val_mae: 12.0233 - val_mape: 276.4328 - val_rmse: 17.6848\n",
      "Epoch 95/100\n",
      "509/509 [==============================] - 1s 3ms/step - loss: 238.0318 - msle: 0.3353 - mae: 10.1245 - mape: 1137.6093 - rmse: 15.4283 - val_loss: 383.2447 - val_msle: 0.3485 - val_mae: 13.1875 - val_mape: 224.9231 - val_rmse: 19.5766\n",
      "Epoch 96/100\n",
      "509/509 [==============================] - 2s 3ms/step - loss: 238.0147 - msle: 0.3425 - mae: 10.1321 - mape: 936.8744 - rmse: 15.4277 - val_loss: 336.8937 - val_msle: 0.3609 - val_mae: 12.6243 - val_mape: 255.8795 - val_rmse: 18.3547\n",
      "Epoch 97/100\n",
      "509/509 [==============================] - 1s 3ms/step - loss: 238.0157 - msle: 0.3370 - mae: 10.1007 - mape: 1044.9701 - rmse: 15.4278 - val_loss: 272.3669 - val_msle: 0.3284 - val_mae: 11.2848 - val_mape: 265.9446 - val_rmse: 16.5035\n",
      "Epoch 98/100\n",
      "509/509 [==============================] - 2s 3ms/step - loss: 236.0905 - msle: 0.3357 - mae: 10.0863 - mape: 1009.9249 - rmse: 15.3652 - val_loss: 393.9491 - val_msle: 0.3489 - val_mae: 13.3602 - val_mape: 222.9368 - val_rmse: 19.8482\n",
      "Epoch 99/100\n",
      "509/509 [==============================] - 2s 3ms/step - loss: 236.1983 - msle: 0.3385 - mae: 10.1179 - mape: 1045.3861 - rmse: 15.3687 - val_loss: 230.5942 - val_msle: 0.3364 - val_mae: 10.2299 - val_mape: 277.5287 - val_rmse: 15.1853\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/100\n",
      "509/509 [==============================] - 2s 5ms/step - loss: 235.7931 - msle: 0.3385 - mae: 10.0620 - mape: 998.1314 - rmse: 15.3556 - val_loss: 328.8951 - val_msle: 0.3393 - val_mae: 12.2741 - val_mape: 247.7755 - val_rmse: 18.1355\n",
      "Wall time: 3min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "rmse_loss = []\n",
    "history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=100)\n",
    "rmse_loss += history.history['rmse']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x20203f6f6a0>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(rmse_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.495854364587164"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sqrt(mean_squared_error(y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
