# Assignment 30/07/2020

|Linear Model Parameters       |Hidden Layers                                               |Activation Function                                    |Optimizer|Learning Rate|Epochs|Train MSE   |Train MAE|Val MSE     |Val MAE  |Train MSLE|Val MSLE|
|:----------------------------:|:----------------------------------------------------------:|:-----------------------------------------------------:|:-------:|:-----------:|:----:|:----------:|:-------:|:----------:|:-------:|:--------:|:------:|
|3 Fully Connected Layers Model|Neurons per hidden layer -> [130, 65, 1]                    |relu for the full network                              |Adam     |0.001        |10    |4178527.5000|1281.1110|4390726.0000|1234.6630|          |        |
|3 Fully Connected Layers Model|Neurons per hidden layer -> [130, 65, 1]                    |relu for the full network                              |Adam     |0.001        |20    |4089867.7500|1264.1523|4240632.0000|1239.1173|          |        |
|3 Fully Connected Layers Model|Neurons per hidden layer -> [130, 65, 1]                    |relu for the full network                              |Adam     |0.001        |50    |3968502.7500|1250.9556|4281258.0000|1229.0972|          |        |
|3 Fully Connected Layers Model|Neurons per hidden layer -> [130, 65, 1]                    |relu for the full network                              |Adam     |0.001        |100   |3885934.2500|1236.2449|4119948.5000|1228.3715|          |        |
|3 Fully Connected Layers Model|Neurons per hidden layer -> [130, 65, 1]                    |relu for the full network                              |Adam     |0.001        |500   |3546600.5000|1195.4869|4309686.5000|1238.6261|          |        |
|3 Fully Connected Layers Model|Neurons per hidden layer -> [130, 65, 1]                    |relu for the full network                              |Adam     |0.001        |1000  |3261451.0000|1168.1522|4606204.5000|1270.4216|          |        |
|3 Fully Connected Layers Model|Neurons per hidden layer -> [130, 65, 1]                    |relu for the full network                              |Adam     |0.001        |5000  |3035758.2500|1147.9901|5281517.0000|1363.9896|          |        |
|3 Fully Connected Layers Model|Neurons per hidden layer -> [130, 65, 1]                    |linear for the full network                            |Adam     |0.001        |10    |4435840.5000|1350.2988|4683775.5000|1329.4232|          |        |
|3 Fully Connected Layers Model|Neurons per hidden layer -> [130, 65, 1]                    |linear for the full network                            |Adam     |0.001        |20    |4412040.0000|1346.2072|4706087.0000|1413.1097|          |        |
|3 Fully Connected Layers Model|Neurons per hidden layer -> [130, 65, 1]                    |linear for the full network                            |Adam     |0.001        |50    |4397436.5000|1343.8987|4824719.0000|1336.1906|          |        |
|3 Fully Connected Layers Model|Neurons per hidden layer -> [130, 65, 1]                    |linear for the full network                            |Adam     |0.001        |100   |4393944.5000|1341.8081|4697675.0000|1337.0493|          |        |
|3 Fully Connected Layers Model|Neurons per hidden layer -> [130, 65, 1]                    |linear for the full network                            |Adam     |0.001        |500   |4396016.0000|1342.9451|4636329.5000|1355.3977|          |        |
|3 Fully Connected Layers Model|Neurons per hidden layer -> [130, 65, 1]                    |linear for the full network                            |Adam     |0.001        |1000  |4374688.5000|1337.5750|4685441.5000|1328.3018|          |        |
|3 Fully Connected Layers Model|Neurons per hidden layer -> [130, 65, 1]                    |linear for the full network                            |Adam     |0.001        |5000  |4390153.0000|1341.1603|4749785.0000|1319.6615|          |        |
|4 Fully Connected Layers Model|Neurons per hidden layer -> [260, 130, 65, 1]               |linear for the last layer and relu for the other layers|Adam     |0.001        |100   |3885363.7500|1227.5720|3988240.0000|1347.0333|          |        |
|4 Fully Connected Layers Model|Neurons per hidden layer -> [260, 130, 65, 1]               |linear for the last layer and relu for the other layers|Adam     |0.001        |500   |2841460.0000|1119.0825|4414667.5000|1291.5073|          |        |
|4 Fully Connected Layers Model|Neurons per hidden layer -> [260, 130, 65, 1]               |linear for the last layer and relu for the other layers|Adam     |0.001        |1000  |2275388.0000|1038.3757|5256642.0000|1353.8179|          |        |
|4 Fully Connected Layers Model|Neurons per hidden layer -> [260, 130, 65, 1]               |linear for the last layer and relu for the other layers|Adam     |0.001        |5000  |||||          |        |
|7 Fully Connected Layers Model|Neurons per hidden layer -> [260, 520, 260, 130, 65, 32, 1]*|linear for the last layer and relu for the other layers|Adam     |0.001        |100   |4670716.5000|1349.6895|3875548.7500|1276.5627|          |        |
|7 Fully Connected Layers Model|Neurons per hidden layer -> [260, 520, 260, 130, 65, 32, 1]*|linear for the last layer and relu for the other layers|Adam     |0.001        |500   |||||          |        |
|7 Fully Connected Layers Model|Neurons per hidden layer -> [260, 520, 260, 130, 65, 32, 1]*|linear for the last layer and relu for the other layers|Adam     |0.001        |1000  |||||          |        |
|7 Fully Connected Layers Model|Neurons per hidden layer -> [260, 520, 260, 130, 65, 32, 1]*|linear for the last layer and relu for the other layers|Adam     |0.001        |5000  |||||          |        |


*Dropout attachment used in the 1st and 3rd hidden layer of probability 0.3. Dropout attachment has been added in the 2nd hidden layer of 0.4 probability. Dropout attachment of 0.2 probability has been added to 4th hidden layer. Dropout attachment of 0.1 probability has been added to the 5th hidden layer.