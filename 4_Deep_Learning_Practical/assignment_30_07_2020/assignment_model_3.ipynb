{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow.keras as kera\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization, Dropout, Input, Flatten\n",
    "from tensorflow.keras.losses import BinaryCrossentropy, CategoricalCrossentropy, SparseCategoricalCrossentropy, MeanSquaredError\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
    "from tensorflow.keras.activations import linear, relu\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from numpy import sqrt\n",
    "\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('./data/train.csv')\n",
    "test_df = pd.read_csv('./data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>col_1</th>\n",
       "      <th>col_2</th>\n",
       "      <th>col_3</th>\n",
       "      <th>col_4</th>\n",
       "      <th>col_5</th>\n",
       "      <th>col_6</th>\n",
       "      <th>col_7</th>\n",
       "      <th>col_8</th>\n",
       "      <th>col_9</th>\n",
       "      <th>...</th>\n",
       "      <th>col_122</th>\n",
       "      <th>col_123</th>\n",
       "      <th>col_124</th>\n",
       "      <th>col_125</th>\n",
       "      <th>col_126</th>\n",
       "      <th>col_127</th>\n",
       "      <th>col_128</th>\n",
       "      <th>col_129</th>\n",
       "      <th>col_130</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>...</td>\n",
       "      <td>0.438917</td>\n",
       "      <td>0.436585</td>\n",
       "      <td>0.60087</td>\n",
       "      <td>0.35127</td>\n",
       "      <td>0.43919</td>\n",
       "      <td>0.338312</td>\n",
       "      <td>0.366307</td>\n",
       "      <td>0.611431</td>\n",
       "      <td>0.304496</td>\n",
       "      <td>1283.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>...</td>\n",
       "      <td>0.289648</td>\n",
       "      <td>0.315545</td>\n",
       "      <td>0.27320</td>\n",
       "      <td>0.26076</td>\n",
       "      <td>0.32446</td>\n",
       "      <td>0.381398</td>\n",
       "      <td>0.373424</td>\n",
       "      <td>0.195709</td>\n",
       "      <td>0.774425</td>\n",
       "      <td>3005.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>...</td>\n",
       "      <td>0.440945</td>\n",
       "      <td>0.391128</td>\n",
       "      <td>0.31796</td>\n",
       "      <td>0.32128</td>\n",
       "      <td>0.44467</td>\n",
       "      <td>0.327915</td>\n",
       "      <td>0.321570</td>\n",
       "      <td>0.605077</td>\n",
       "      <td>0.602642</td>\n",
       "      <td>939.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>...</td>\n",
       "      <td>0.178193</td>\n",
       "      <td>0.247408</td>\n",
       "      <td>0.24564</td>\n",
       "      <td>0.22089</td>\n",
       "      <td>0.21230</td>\n",
       "      <td>0.204687</td>\n",
       "      <td>0.202213</td>\n",
       "      <td>0.246011</td>\n",
       "      <td>0.432606</td>\n",
       "      <td>2763.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>...</td>\n",
       "      <td>0.364464</td>\n",
       "      <td>0.401162</td>\n",
       "      <td>0.26847</td>\n",
       "      <td>0.46226</td>\n",
       "      <td>0.50556</td>\n",
       "      <td>0.366788</td>\n",
       "      <td>0.359249</td>\n",
       "      <td>0.345247</td>\n",
       "      <td>0.726792</td>\n",
       "      <td>5142.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>14</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>...</td>\n",
       "      <td>0.381515</td>\n",
       "      <td>0.363768</td>\n",
       "      <td>0.24564</td>\n",
       "      <td>0.40455</td>\n",
       "      <td>0.47225</td>\n",
       "      <td>0.334828</td>\n",
       "      <td>0.352251</td>\n",
       "      <td>0.342239</td>\n",
       "      <td>0.382931</td>\n",
       "      <td>1132.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>...</td>\n",
       "      <td>0.867021</td>\n",
       "      <td>0.583389</td>\n",
       "      <td>0.90267</td>\n",
       "      <td>0.84847</td>\n",
       "      <td>0.80218</td>\n",
       "      <td>0.644013</td>\n",
       "      <td>0.785706</td>\n",
       "      <td>0.859764</td>\n",
       "      <td>0.242416</td>\n",
       "      <td>3585.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>23</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>...</td>\n",
       "      <td>0.628534</td>\n",
       "      <td>0.384099</td>\n",
       "      <td>0.61229</td>\n",
       "      <td>0.38249</td>\n",
       "      <td>0.51111</td>\n",
       "      <td>0.682315</td>\n",
       "      <td>0.669033</td>\n",
       "      <td>0.756454</td>\n",
       "      <td>0.361191</td>\n",
       "      <td>10280.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>24</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>...</td>\n",
       "      <td>0.713343</td>\n",
       "      <td>0.469223</td>\n",
       "      <td>0.30260</td>\n",
       "      <td>0.67135</td>\n",
       "      <td>0.83510</td>\n",
       "      <td>0.863052</td>\n",
       "      <td>0.879347</td>\n",
       "      <td>0.822493</td>\n",
       "      <td>0.294523</td>\n",
       "      <td>6184.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>33</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>...</td>\n",
       "      <td>0.314683</td>\n",
       "      <td>0.370419</td>\n",
       "      <td>0.58354</td>\n",
       "      <td>0.46226</td>\n",
       "      <td>0.38016</td>\n",
       "      <td>0.644013</td>\n",
       "      <td>0.665644</td>\n",
       "      <td>0.339244</td>\n",
       "      <td>0.799124</td>\n",
       "      <td>5965.73</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 132 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id col_1 col_2 col_3 col_4 col_5 col_6 col_7 col_8 col_9  ...   col_122  \\\n",
       "0   2     A     B     A     A     A     A     A     A     B  ...  0.438917   \n",
       "1   5     A     B     A     A     B     A     A     A     B  ...  0.289648   \n",
       "2  10     B     B     A     B     A     A     A     A     B  ...  0.440945   \n",
       "3  11     A     B     A     B     A     A     A     A     B  ...  0.178193   \n",
       "4  13     A     B     A     A     A     A     A     A     B  ...  0.364464   \n",
       "5  14     A     A     A     A     B     A     A     A     A  ...  0.381515   \n",
       "6  20     A     B     A     B     A     A     A     A     B  ...  0.867021   \n",
       "7  23     A     B     B     B     B     A     A     A     B  ...  0.628534   \n",
       "8  24     A     B     A     A     B     B     A     A     B  ...  0.713343   \n",
       "9  33     A     B     A     A     B     A     A     A     B  ...  0.314683   \n",
       "\n",
       "    col_123  col_124  col_125  col_126   col_127   col_128   col_129  \\\n",
       "0  0.436585  0.60087  0.35127  0.43919  0.338312  0.366307  0.611431   \n",
       "1  0.315545  0.27320  0.26076  0.32446  0.381398  0.373424  0.195709   \n",
       "2  0.391128  0.31796  0.32128  0.44467  0.327915  0.321570  0.605077   \n",
       "3  0.247408  0.24564  0.22089  0.21230  0.204687  0.202213  0.246011   \n",
       "4  0.401162  0.26847  0.46226  0.50556  0.366788  0.359249  0.345247   \n",
       "5  0.363768  0.24564  0.40455  0.47225  0.334828  0.352251  0.342239   \n",
       "6  0.583389  0.90267  0.84847  0.80218  0.644013  0.785706  0.859764   \n",
       "7  0.384099  0.61229  0.38249  0.51111  0.682315  0.669033  0.756454   \n",
       "8  0.469223  0.30260  0.67135  0.83510  0.863052  0.879347  0.822493   \n",
       "9  0.370419  0.58354  0.46226  0.38016  0.644013  0.665644  0.339244   \n",
       "\n",
       "    col_130    target  \n",
       "0  0.304496   1283.60  \n",
       "1  0.774425   3005.09  \n",
       "2  0.602642    939.85  \n",
       "3  0.432606   2763.85  \n",
       "4  0.726792   5142.87  \n",
       "5  0.382931   1132.22  \n",
       "6  0.242416   3585.75  \n",
       "7  0.361191  10280.20  \n",
       "8  0.294523   6184.59  \n",
       "9  0.799124   5965.73  \n",
       "\n",
       "[10 rows x 132 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>col_1</th>\n",
       "      <th>col_2</th>\n",
       "      <th>col_3</th>\n",
       "      <th>col_4</th>\n",
       "      <th>col_5</th>\n",
       "      <th>col_6</th>\n",
       "      <th>col_7</th>\n",
       "      <th>col_8</th>\n",
       "      <th>col_9</th>\n",
       "      <th>...</th>\n",
       "      <th>col_122</th>\n",
       "      <th>col_123</th>\n",
       "      <th>col_124</th>\n",
       "      <th>col_125</th>\n",
       "      <th>col_126</th>\n",
       "      <th>col_127</th>\n",
       "      <th>col_128</th>\n",
       "      <th>col_129</th>\n",
       "      <th>col_130</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>169476</th>\n",
       "      <td>587605</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>...</td>\n",
       "      <td>0.599275</td>\n",
       "      <td>0.548122</td>\n",
       "      <td>0.48864</td>\n",
       "      <td>0.45391</td>\n",
       "      <td>0.64056</td>\n",
       "      <td>0.592525</td>\n",
       "      <td>0.590961</td>\n",
       "      <td>0.701266</td>\n",
       "      <td>0.362479</td>\n",
       "      <td>1173.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169477</th>\n",
       "      <td>587606</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>...</td>\n",
       "      <td>0.201125</td>\n",
       "      <td>0.259395</td>\n",
       "      <td>0.24564</td>\n",
       "      <td>0.30859</td>\n",
       "      <td>0.21983</td>\n",
       "      <td>0.207238</td>\n",
       "      <td>0.204687</td>\n",
       "      <td>0.357400</td>\n",
       "      <td>0.348217</td>\n",
       "      <td>2161.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169478</th>\n",
       "      <td>587607</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>...</td>\n",
       "      <td>0.269520</td>\n",
       "      <td>0.338963</td>\n",
       "      <td>0.33906</td>\n",
       "      <td>0.28066</td>\n",
       "      <td>0.30529</td>\n",
       "      <td>0.245410</td>\n",
       "      <td>0.261799</td>\n",
       "      <td>0.181433</td>\n",
       "      <td>0.398571</td>\n",
       "      <td>4080.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169479</th>\n",
       "      <td>587612</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>...</td>\n",
       "      <td>0.502705</td>\n",
       "      <td>0.473897</td>\n",
       "      <td>0.43518</td>\n",
       "      <td>0.66201</td>\n",
       "      <td>0.58257</td>\n",
       "      <td>0.415029</td>\n",
       "      <td>0.406090</td>\n",
       "      <td>0.354344</td>\n",
       "      <td>0.377315</td>\n",
       "      <td>994.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169480</th>\n",
       "      <td>587619</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>...</td>\n",
       "      <td>0.445008</td>\n",
       "      <td>0.377930</td>\n",
       "      <td>0.36636</td>\n",
       "      <td>0.29095</td>\n",
       "      <td>0.44467</td>\n",
       "      <td>0.327915</td>\n",
       "      <td>0.321570</td>\n",
       "      <td>0.731059</td>\n",
       "      <td>0.721499</td>\n",
       "      <td>804.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169481</th>\n",
       "      <td>587620</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>...</td>\n",
       "      <td>0.242437</td>\n",
       "      <td>0.289949</td>\n",
       "      <td>0.24564</td>\n",
       "      <td>0.30859</td>\n",
       "      <td>0.32935</td>\n",
       "      <td>0.223038</td>\n",
       "      <td>0.220003</td>\n",
       "      <td>0.333292</td>\n",
       "      <td>0.208216</td>\n",
       "      <td>1198.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169482</th>\n",
       "      <td>587624</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>...</td>\n",
       "      <td>0.334270</td>\n",
       "      <td>0.382000</td>\n",
       "      <td>0.63475</td>\n",
       "      <td>0.40455</td>\n",
       "      <td>0.47779</td>\n",
       "      <td>0.307628</td>\n",
       "      <td>0.301921</td>\n",
       "      <td>0.318646</td>\n",
       "      <td>0.305872</td>\n",
       "      <td>1108.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169483</th>\n",
       "      <td>587630</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>...</td>\n",
       "      <td>0.345883</td>\n",
       "      <td>0.370534</td>\n",
       "      <td>0.24564</td>\n",
       "      <td>0.45808</td>\n",
       "      <td>0.47779</td>\n",
       "      <td>0.445614</td>\n",
       "      <td>0.443374</td>\n",
       "      <td>0.339244</td>\n",
       "      <td>0.503888</td>\n",
       "      <td>5762.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169484</th>\n",
       "      <td>587632</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>...</td>\n",
       "      <td>0.704364</td>\n",
       "      <td>0.562866</td>\n",
       "      <td>0.34987</td>\n",
       "      <td>0.44767</td>\n",
       "      <td>0.53881</td>\n",
       "      <td>0.863052</td>\n",
       "      <td>0.852865</td>\n",
       "      <td>0.654753</td>\n",
       "      <td>0.721707</td>\n",
       "      <td>1562.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169485</th>\n",
       "      <td>587633</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>...</td>\n",
       "      <td>0.844563</td>\n",
       "      <td>0.533048</td>\n",
       "      <td>0.97123</td>\n",
       "      <td>0.93383</td>\n",
       "      <td>0.83814</td>\n",
       "      <td>0.932195</td>\n",
       "      <td>0.946432</td>\n",
       "      <td>0.810511</td>\n",
       "      <td>0.721460</td>\n",
       "      <td>4751.72</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 132 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id col_1 col_2 col_3 col_4 col_5 col_6 col_7 col_8 col_9  ...  \\\n",
       "169476  587605     B     A     A     A     A     B     A     A     A  ...   \n",
       "169477  587606     A     A     A     A     B     A     A     A     A  ...   \n",
       "169478  587607     A     B     A     B     B     B     A     A     B  ...   \n",
       "169479  587612     A     A     A     A     B     A     A     A     A  ...   \n",
       "169480  587619     A     A     A     A     A     B     A     A     A  ...   \n",
       "169481  587620     A     B     A     A     A     A     A     A     B  ...   \n",
       "169482  587624     A     A     A     A     A     B     A     A     A  ...   \n",
       "169483  587630     A     B     A     A     A     A     A     B     B  ...   \n",
       "169484  587632     A     B     A     A     A     A     A     A     B  ...   \n",
       "169485  587633     B     A     A     B     A     A     A     A     A  ...   \n",
       "\n",
       "         col_122   col_123  col_124  col_125  col_126   col_127   col_128  \\\n",
       "169476  0.599275  0.548122  0.48864  0.45391  0.64056  0.592525  0.590961   \n",
       "169477  0.201125  0.259395  0.24564  0.30859  0.21983  0.207238  0.204687   \n",
       "169478  0.269520  0.338963  0.33906  0.28066  0.30529  0.245410  0.261799   \n",
       "169479  0.502705  0.473897  0.43518  0.66201  0.58257  0.415029  0.406090   \n",
       "169480  0.445008  0.377930  0.36636  0.29095  0.44467  0.327915  0.321570   \n",
       "169481  0.242437  0.289949  0.24564  0.30859  0.32935  0.223038  0.220003   \n",
       "169482  0.334270  0.382000  0.63475  0.40455  0.47779  0.307628  0.301921   \n",
       "169483  0.345883  0.370534  0.24564  0.45808  0.47779  0.445614  0.443374   \n",
       "169484  0.704364  0.562866  0.34987  0.44767  0.53881  0.863052  0.852865   \n",
       "169485  0.844563  0.533048  0.97123  0.93383  0.83814  0.932195  0.946432   \n",
       "\n",
       "         col_129   col_130   target  \n",
       "169476  0.701266  0.362479  1173.30  \n",
       "169477  0.357400  0.348217  2161.12  \n",
       "169478  0.181433  0.398571  4080.42  \n",
       "169479  0.354344  0.377315   994.85  \n",
       "169480  0.731059  0.721499   804.28  \n",
       "169481  0.333292  0.208216  1198.62  \n",
       "169482  0.318646  0.305872  1108.34  \n",
       "169483  0.339244  0.503888  5762.64  \n",
       "169484  0.654753  0.721707  1562.87  \n",
       "169485  0.810511  0.721460  4751.72  \n",
       "\n",
       "[10 rows x 132 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 12.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cat = [f'col_{i}' for i in range(1, 117)]\n",
    "con = [f'col_{i}' for i in range(117, 131)]\n",
    "for c in cat:\n",
    "    train_df[c] = train_df[c].astype('category')\n",
    "    test_df[c] = test_df[c].astype('category')\n",
    "    train_df[c] = train_df[c].cat.codes\n",
    "    test_df[c] = test_df[c].cat.codes\n",
    "del c\n",
    "train_df.drop('id', axis=1, inplace=True)\n",
    "test_df.drop('id', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['col_1', 'col_2', 'col_3', 'col_4', 'col_5', 'col_6', 'col_7', 'col_8',\n",
       "       'col_9', 'col_10',\n",
       "       ...\n",
       "       'col_122', 'col_123', 'col_124', 'col_125', 'col_126', 'col_127',\n",
       "       'col_128', 'col_129', 'col_130', 'target'],\n",
       "      dtype='object', length=131)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_df.iloc[:,train_df.columns != 'target'].values\n",
    "y = train_df.iloc[:,train_df.columns == 'target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train)\n",
    "del X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(95335, 130)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 260)               34060     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 130)               33930     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 65)                8515      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 66        \n",
      "=================================================================\n",
      "Total params: 76,571\n",
      "Trainable params: 76,571\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "activation_fn = 'relu'\n",
    "model = Sequential()\n",
    "model.add(Input(shape=(130,)))\n",
    "model.add(Dense(260, activation=activation_fn))\n",
    "model.add(Dense(130, activation=activation_fn))\n",
    "model.add(Dense(65, activation=activation_fn))\n",
    "model.add(Dense(1, activation=linear))\n",
    "model.compile(optimizer=RMSprop(learning_rate=1e-3), loss=MeanSquaredError(), metrics=['mse', 'mae'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_history = []\n",
    "mae_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2980/2980 [==============================] - 13s 4ms/step - loss: 5424851.5000 - mse: 5424851.5000 - mae: 1459.7018 - val_loss: 5032704.5000 - val_mse: 5032704.5000 - val_mae: 1697.2418\n",
      "Epoch 2/100\n",
      "2980/2980 [==============================] - 14s 5ms/step - loss: 4593660.0000 - mse: 4593660.0000 - mae: 1334.7026 - val_loss: 4005077.2500 - val_mse: 4005077.2500 - val_mae: 1316.4584\n",
      "Epoch 3/100\n",
      "2980/2980 [==============================] - 12s 4ms/step - loss: 4507337.0000 - mse: 4507337.0000 - mae: 1317.4562 - val_loss: 3945072.7500 - val_mse: 3945072.7500 - val_mae: 1260.7466\n",
      "Epoch 4/100\n",
      "2980/2980 [==============================] - 8s 3ms/step - loss: 4454946.0000 - mse: 4454946.0000 - mae: 1306.9351 - val_loss: 3998572.7500 - val_mse: 3998572.7500 - val_mae: 1245.2523\n",
      "Epoch 5/100\n",
      "2980/2980 [==============================] - 8s 3ms/step - loss: 4402723.0000 - mse: 4402723.0000 - mae: 1299.6893 - val_loss: 4432255.5000 - val_mse: 4432255.5000 - val_mae: 1260.9688\n",
      "Epoch 6/100\n",
      "2980/2980 [==============================] - 9s 3ms/step - loss: 4379609.5000 - mse: 4379609.5000 - mae: 1294.9401 - val_loss: 4000745.0000 - val_mse: 4000745.0000 - val_mae: 1357.9562\n",
      "Epoch 7/100\n",
      "2980/2980 [==============================] - 9s 3ms/step - loss: 4353092.0000 - mse: 4353092.0000 - mae: 1291.2860 - val_loss: 4789140.5000 - val_mse: 4789140.5000 - val_mae: 1281.9822\n",
      "Epoch 8/100\n",
      "2980/2980 [==============================] - 8s 3ms/step - loss: 4316240.0000 - mse: 4316240.0000 - mae: 1285.4050 - val_loss: 4310101.0000 - val_mse: 4310101.0000 - val_mae: 1522.1783\n",
      "Epoch 9/100\n",
      "2980/2980 [==============================] - 8s 3ms/step - loss: 4307835.0000 - mse: 4307835.0000 - mae: 1284.9998 - val_loss: 3826906.7500 - val_mse: 3826906.7500 - val_mae: 1243.3770\n",
      "Epoch 10/100\n",
      "2980/2980 [==============================] - 9s 3ms/step - loss: 4279244.0000 - mse: 4279244.0000 - mae: 1279.5219 - val_loss: 4003664.7500 - val_mse: 4003664.7500 - val_mae: 1235.1736\n",
      "Epoch 11/100\n",
      "2980/2980 [==============================] - 9s 3ms/step - loss: 4277297.5000 - mse: 4277297.5000 - mae: 1279.8065 - val_loss: 4356128.0000 - val_mse: 4356128.0000 - val_mae: 1254.4003\n",
      "Epoch 12/100\n",
      "2980/2980 [==============================] - 8s 3ms/step - loss: 4253538.5000 - mse: 4253538.5000 - mae: 1277.4910 - val_loss: 3804858.0000 - val_mse: 3804858.0000 - val_mae: 1284.8673\n",
      "Epoch 13/100\n",
      "2980/2980 [==============================] - 9s 3ms/step - loss: 4244456.0000 - mse: 4244456.0000 - mae: 1273.5157 - val_loss: 4137027.2500 - val_mse: 4137027.2500 - val_mae: 1250.9436\n",
      "Epoch 14/100\n",
      "2980/2980 [==============================] - 9s 3ms/step - loss: 4238269.0000 - mse: 4238269.0000 - mae: 1273.6185 - val_loss: 4057491.5000 - val_mse: 4057491.5000 - val_mae: 1228.8232\n",
      "Epoch 15/100\n",
      "2980/2980 [==============================] - 9s 3ms/step - loss: 4221429.0000 - mse: 4221429.0000 - mae: 1271.3610 - val_loss: 4434278.0000 - val_mse: 4434278.0000 - val_mae: 1495.0222\n",
      "Epoch 16/100\n",
      "2980/2980 [==============================] - 8s 3ms/step - loss: 4205111.0000 - mse: 4205111.0000 - mae: 1269.9780 - val_loss: 4074020.0000 - val_mse: 4074020.0000 - val_mae: 1222.8969\n",
      "Epoch 17/100\n",
      "2980/2980 [==============================] - 8s 3ms/step - loss: 4200627.5000 - mse: 4200627.5000 - mae: 1269.9591 - val_loss: 3755064.7500 - val_mse: 3755064.7500 - val_mae: 1237.4138\n",
      "Epoch 18/100\n",
      "2980/2980 [==============================] - 10s 3ms/step - loss: 4188491.5000 - mse: 4188491.5000 - mae: 1264.8026 - val_loss: 3812135.7500 - val_mse: 3812135.7500 - val_mae: 1233.3721\n",
      "Epoch 19/100\n",
      "2980/2980 [==============================] - 9s 3ms/step - loss: 4188177.7500 - mse: 4188177.7500 - mae: 1266.4303 - val_loss: 3734078.5000 - val_mse: 3734078.5000 - val_mae: 1255.4740\n",
      "Epoch 20/100\n",
      "2980/2980 [==============================] - 8s 3ms/step - loss: 4180436.7500 - mse: 4180436.7500 - mae: 1265.0903 - val_loss: 3803310.0000 - val_mse: 3803310.0000 - val_mae: 1217.6368\n",
      "Epoch 21/100\n",
      "2980/2980 [==============================] - 8s 3ms/step - loss: 4178139.0000 - mse: 4178139.0000 - mae: 1263.9741 - val_loss: 3787589.7500 - val_mse: 3787589.7500 - val_mae: 1286.2581\n",
      "Epoch 22/100\n",
      "2980/2980 [==============================] - 8s 3ms/step - loss: 4150152.5000 - mse: 4150152.5000 - mae: 1262.6617 - val_loss: 3810365.5000 - val_mse: 3810365.5000 - val_mae: 1237.7358\n",
      "Epoch 23/100\n",
      "2980/2980 [==============================] - 9s 3ms/step - loss: 4159616.2500 - mse: 4159616.2500 - mae: 1260.6545 - val_loss: 3769949.0000 - val_mse: 3769949.0000 - val_mae: 1281.3430\n",
      "Epoch 24/100\n",
      "2980/2980 [==============================] - 8s 3ms/step - loss: 4146782.7500 - mse: 4146782.7500 - mae: 1260.5986 - val_loss: 4466982.0000 - val_mse: 4466982.0000 - val_mae: 1540.2827\n",
      "Epoch 25/100\n",
      "2980/2980 [==============================] - 8s 3ms/step - loss: 4145670.2500 - mse: 4145670.2500 - mae: 1260.3085 - val_loss: 3775408.7500 - val_mse: 3775408.7500 - val_mae: 1233.1813\n",
      "Epoch 26/100\n",
      "2980/2980 [==============================] - 8s 3ms/step - loss: 4138872.7500 - mse: 4138872.7500 - mae: 1257.5803 - val_loss: 4989656.0000 - val_mse: 4989656.0000 - val_mae: 1644.4412\n",
      "Epoch 27/100\n",
      "2980/2980 [==============================] - 8s 3ms/step - loss: 4140590.0000 - mse: 4140590.0000 - mae: 1258.3160 - val_loss: 3752826.2500 - val_mse: 3752826.2500 - val_mae: 1239.0167\n",
      "Epoch 28/100\n",
      "2980/2980 [==============================] - 8s 3ms/step - loss: 4134313.5000 - mse: 4134313.5000 - mae: 1257.7388 - val_loss: 3745681.2500 - val_mse: 3745681.2500 - val_mae: 1257.3898\n",
      "Epoch 29/100\n",
      "2980/2980 [==============================] - 8s 3ms/step - loss: 4128247.0000 - mse: 4128247.0000 - mae: 1257.5280 - val_loss: 3788340.0000 - val_mse: 3788340.0000 - val_mae: 1291.3926\n",
      "Epoch 30/100\n",
      "2980/2980 [==============================] - 8s 3ms/step - loss: 4116428.7500 - mse: 4116428.7500 - mae: 1257.4945 - val_loss: 3743574.7500 - val_mse: 3743574.7500 - val_mae: 1232.9165\n",
      "Epoch 31/100\n",
      "2980/2980 [==============================] - 8s 3ms/step - loss: 4109101.0000 - mse: 4109101.0000 - mae: 1255.1423 - val_loss: 3881943.7500 - val_mse: 3881943.7500 - val_mae: 1213.5825\n",
      "Epoch 32/100\n",
      "2980/2980 [==============================] - 8s 3ms/step - loss: 4119852.5000 - mse: 4119852.5000 - mae: 1253.8688 - val_loss: 4781874.0000 - val_mse: 4781874.0000 - val_mae: 1482.3647\n",
      "Epoch 33/100\n",
      "2980/2980 [==============================] - 7s 2ms/step - loss: 4094605.2500 - mse: 4094605.2500 - mae: 1252.6923 - val_loss: 3778798.0000 - val_mse: 3778798.0000 - val_mae: 1228.0426\n",
      "Epoch 34/100\n",
      "2980/2980 [==============================] - 8s 3ms/step - loss: 4093236.5000 - mse: 4093236.5000 - mae: 1252.9634 - val_loss: 3852490.5000 - val_mse: 3852490.5000 - val_mae: 1238.2942\n",
      "Epoch 35/100\n",
      "2980/2980 [==============================] - 8s 3ms/step - loss: 4100276.2500 - mse: 4100276.2500 - mae: 1251.9346 - val_loss: 3738240.0000 - val_mse: 3738240.0000 - val_mae: 1244.2909\n",
      "Epoch 36/100\n",
      "2980/2980 [==============================] - 8s 3ms/step - loss: 4085762.2500 - mse: 4085762.2500 - mae: 1250.2642 - val_loss: 3913205.2500 - val_mse: 3913205.2500 - val_mae: 1222.0977\n",
      "Epoch 37/100\n",
      "2980/2980 [==============================] - 9s 3ms/step - loss: 4060194.2500 - mse: 4060194.2500 - mae: 1247.9983 - val_loss: 3759784.5000 - val_mse: 3759784.5000 - val_mae: 1271.6556\n",
      "Epoch 38/100\n",
      "2980/2980 [==============================] - 8s 3ms/step - loss: 4090114.0000 - mse: 4090114.0000 - mae: 1251.7650 - val_loss: 3733346.2500 - val_mse: 3733346.2500 - val_mae: 1243.7098\n",
      "Epoch 39/100\n",
      "2980/2980 [==============================] - 9s 3ms/step - loss: 4075373.7500 - mse: 4075373.7500 - mae: 1249.0012 - val_loss: 3760768.2500 - val_mse: 3760768.2500 - val_mae: 1216.2264\n",
      "Epoch 40/100\n",
      "2980/2980 [==============================] - 7s 2ms/step - loss: 4084113.2500 - mse: 4084113.2500 - mae: 1250.3868 - val_loss: 3713546.5000 - val_mse: 3713546.5000 - val_mae: 1259.8431\n",
      "Epoch 41/100\n",
      "2980/2980 [==============================] - 8s 3ms/step - loss: 4064968.5000 - mse: 4064968.5000 - mae: 1247.0746 - val_loss: 3854962.5000 - val_mse: 3854962.5000 - val_mae: 1222.4988\n",
      "Epoch 42/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2980/2980 [==============================] - 9s 3ms/step - loss: 4051342.0000 - mse: 4051342.0000 - mae: 1248.0057 - val_loss: 3850156.5000 - val_mse: 3850156.5000 - val_mae: 1220.4028\n",
      "Epoch 43/100\n",
      "2980/2980 [==============================] - 8s 3ms/step - loss: 4043752.2500 - mse: 4043752.2500 - mae: 1245.7251 - val_loss: 3915644.7500 - val_mse: 3915644.7500 - val_mae: 1233.1138\n",
      "Epoch 44/100\n",
      "2980/2980 [==============================] - 8s 3ms/step - loss: 4036298.2500 - mse: 4036298.2500 - mae: 1246.8428 - val_loss: 3963083.5000 - val_mse: 3963083.5000 - val_mae: 1216.2889\n",
      "Epoch 45/100\n",
      "2980/2980 [==============================] - 8s 3ms/step - loss: 4060466.7500 - mse: 4060466.7500 - mae: 1246.9309 - val_loss: 3753300.7500 - val_mse: 3753300.7500 - val_mae: 1249.5977\n",
      "Epoch 46/100\n",
      "2980/2980 [==============================] - 8s 3ms/step - loss: 4049607.5000 - mse: 4049607.5000 - mae: 1246.1123 - val_loss: 3781179.2500 - val_mse: 3781179.2500 - val_mae: 1288.1517\n",
      "Epoch 47/100\n",
      "2980/2980 [==============================] - 7s 2ms/step - loss: 4055357.7500 - mse: 4055357.7500 - mae: 1244.7627 - val_loss: 3760226.5000 - val_mse: 3760226.5000 - val_mae: 1261.2281\n",
      "Epoch 48/100\n",
      "2980/2980 [==============================] - 8s 3ms/step - loss: 4062090.2500 - mse: 4062090.2500 - mae: 1245.3252 - val_loss: 3807478.2500 - val_mse: 3807478.2500 - val_mae: 1320.7672\n",
      "Epoch 49/100\n",
      "2980/2980 [==============================] - 8s 3ms/step - loss: 4045412.2500 - mse: 4045412.2500 - mae: 1244.1831 - val_loss: 3908321.7500 - val_mse: 3908321.7500 - val_mae: 1365.2653\n",
      "Epoch 50/100\n",
      "2980/2980 [==============================] - 8s 3ms/step - loss: 4035836.2500 - mse: 4035836.2500 - mae: 1243.9307 - val_loss: 3916928.2500 - val_mse: 3916928.2500 - val_mae: 1213.0283\n",
      "Epoch 51/100\n",
      "2980/2980 [==============================] - 8s 3ms/step - loss: 4032801.0000 - mse: 4032801.0000 - mae: 1244.9097 - val_loss: 3797461.0000 - val_mse: 3797461.0000 - val_mae: 1218.6368\n",
      "Epoch 52/100\n",
      "2980/2980 [==============================] - 7s 2ms/step - loss: 4035059.0000 - mse: 4035059.0000 - mae: 1243.4059 - val_loss: 4029990.7500 - val_mse: 4029990.7500 - val_mae: 1400.8052\n",
      "Epoch 53/100\n",
      "2980/2980 [==============================] - 8s 3ms/step - loss: 4027904.2500 - mse: 4027904.2500 - mae: 1244.4779 - val_loss: 4145630.5000 - val_mse: 4145630.5000 - val_mae: 1234.1750\n",
      "Epoch 54/100\n",
      "2980/2980 [==============================] - 8s 3ms/step - loss: 4030688.5000 - mse: 4030688.5000 - mae: 1243.5347 - val_loss: 3732393.2500 - val_mse: 3732393.2500 - val_mae: 1246.2943\n",
      "Epoch 55/100\n",
      "2980/2980 [==============================] - 7s 3ms/step - loss: 4028812.7500 - mse: 4028812.7500 - mae: 1243.7065 - val_loss: 3894285.0000 - val_mse: 3894285.0000 - val_mae: 1319.4418\n",
      "Epoch 56/100\n",
      "2980/2980 [==============================] - 8s 3ms/step - loss: 4037831.2500 - mse: 4037831.2500 - mae: 1245.0098 - val_loss: 3729812.0000 - val_mse: 3729812.0000 - val_mae: 1262.5919\n",
      "Epoch 57/100\n",
      "2980/2980 [==============================] - 7s 3ms/step - loss: 4024045.2500 - mse: 4024045.2500 - mae: 1243.4042 - val_loss: 3762738.2500 - val_mse: 3762738.2500 - val_mae: 1251.5957\n",
      "Epoch 58/100\n",
      "2980/2980 [==============================] - 8s 3ms/step - loss: 4017839.7500 - mse: 4017839.7500 - mae: 1243.3654 - val_loss: 3788907.5000 - val_mse: 3788907.5000 - val_mae: 1236.2233\n",
      "Epoch 59/100\n",
      "2980/2980 [==============================] - 8s 3ms/step - loss: 4018530.2500 - mse: 4018530.2500 - mae: 1244.2904 - val_loss: 3735911.2500 - val_mse: 3735911.2500 - val_mae: 1272.9570\n",
      "Epoch 60/100\n",
      "2980/2980 [==============================] - 9s 3ms/step - loss: 4007628.0000 - mse: 4007628.0000 - mae: 1242.1476 - val_loss: 3727678.5000 - val_mse: 3727678.5000 - val_mae: 1235.9882\n",
      "Epoch 61/100\n",
      "2980/2980 [==============================] - 8s 3ms/step - loss: 4004182.0000 - mse: 4004182.0000 - mae: 1242.5388 - val_loss: 3815818.5000 - val_mse: 3815818.5000 - val_mae: 1225.7404\n",
      "Epoch 62/100\n",
      "2980/2980 [==============================] - 8s 3ms/step - loss: 3993148.2500 - mse: 3993148.2500 - mae: 1241.0449 - val_loss: 3858791.2500 - val_mse: 3858791.2500 - val_mae: 1336.6569\n",
      "Epoch 63/100\n",
      "2980/2980 [==============================] - 8s 3ms/step - loss: 3998273.7500 - mse: 3998273.7500 - mae: 1240.2278 - val_loss: 4346570.5000 - val_mse: 4346570.5000 - val_mae: 1469.3337\n",
      "Epoch 64/100\n",
      "2980/2980 [==============================] - 8s 3ms/step - loss: 4001253.5000 - mse: 4001253.5000 - mae: 1240.1184 - val_loss: 3759453.5000 - val_mse: 3759453.5000 - val_mae: 1216.5897\n",
      "Epoch 65/100\n",
      "2980/2980 [==============================] - 8s 3ms/step - loss: 3993238.7500 - mse: 3993238.7500 - mae: 1239.3284 - val_loss: 3786185.5000 - val_mse: 3786185.5000 - val_mae: 1272.6461\n",
      "Epoch 66/100\n",
      "2980/2980 [==============================] - 8s 3ms/step - loss: 4001776.2500 - mse: 4001776.2500 - mae: 1239.5096 - val_loss: 3750865.0000 - val_mse: 3750865.0000 - val_mae: 1235.1989\n",
      "Epoch 67/100\n",
      "2980/2980 [==============================] - 8s 3ms/step - loss: 3976312.2500 - mse: 3976312.2500 - mae: 1238.7197 - val_loss: 5294878.0000 - val_mse: 5294878.0000 - val_mae: 1731.4628\n",
      "Epoch 68/100\n",
      "2980/2980 [==============================] - 9s 3ms/step - loss: 3980183.7500 - mse: 3980183.7500 - mae: 1237.4672 - val_loss: 3715630.2500 - val_mse: 3715630.2500 - val_mae: 1257.5099\n",
      "Epoch 69/100\n",
      "2980/2980 [==============================] - 7s 3ms/step - loss: 3990080.7500 - mse: 3990080.7500 - mae: 1239.2186 - val_loss: 3731938.5000 - val_mse: 3731938.5000 - val_mae: 1272.8502\n",
      "Epoch 70/100\n",
      "2980/2980 [==============================] - 8s 3ms/step - loss: 3993867.0000 - mse: 3993867.0000 - mae: 1237.8539 - val_loss: 3759475.0000 - val_mse: 3759475.0000 - val_mae: 1243.1047\n",
      "Epoch 71/100\n",
      "2980/2980 [==============================] - 8s 3ms/step - loss: 3953429.0000 - mse: 3953429.0000 - mae: 1238.1147 - val_loss: 3783578.2500 - val_mse: 3783578.2500 - val_mae: 1226.3751\n",
      "Epoch 72/100\n",
      "2980/2980 [==============================] - 8s 3ms/step - loss: 3973363.7500 - mse: 3973363.7500 - mae: 1238.5400 - val_loss: 3740412.5000 - val_mse: 3740412.5000 - val_mae: 1281.8333\n",
      "Epoch 73/100\n",
      "2980/2980 [==============================] - 9s 3ms/step - loss: 3991813.2500 - mse: 3991813.2500 - mae: 1238.1127 - val_loss: 3785823.0000 - val_mse: 3785823.0000 - val_mae: 1235.8981\n",
      "Epoch 74/100\n",
      "2980/2980 [==============================] - 8s 3ms/step - loss: 3970098.5000 - mse: 3970098.5000 - mae: 1236.6111 - val_loss: 3797920.2500 - val_mse: 3797920.2500 - val_mae: 1220.5398\n",
      "Epoch 75/100\n",
      "2980/2980 [==============================] - 8s 3ms/step - loss: 3967615.5000 - mse: 3967615.5000 - mae: 1235.4142 - val_loss: 4171795.5000 - val_mse: 4171795.5000 - val_mae: 1229.3798\n",
      "Epoch 76/100\n",
      "2980/2980 [==============================] - 8s 3ms/step - loss: 3951410.0000 - mse: 3951410.0000 - mae: 1235.7021 - val_loss: 3749826.5000 - val_mse: 3749826.5000 - val_mae: 1281.5410\n",
      "Epoch 77/100\n",
      "2980/2980 [==============================] - 7s 2ms/step - loss: 3956210.7500 - mse: 3956210.7500 - mae: 1236.1991 - val_loss: 4030977.2500 - val_mse: 4030977.2500 - val_mae: 1342.1335\n",
      "Epoch 78/100\n",
      "2980/2980 [==============================] - 8s 3ms/step - loss: 3955740.7500 - mse: 3955740.7500 - mae: 1237.2142 - val_loss: 3787497.5000 - val_mse: 3787497.5000 - val_mae: 1290.2379\n",
      "Epoch 79/100\n",
      "2980/2980 [==============================] - 8s 3ms/step - loss: 3944767.7500 - mse: 3944767.7500 - mae: 1234.6069 - val_loss: 3851862.2500 - val_mse: 3851862.2500 - val_mae: 1217.2795\n",
      "Epoch 80/100\n",
      "2980/2980 [==============================] - 8s 3ms/step - loss: 3951848.2500 - mse: 3951848.2500 - mae: 1234.6617 - val_loss: 3941527.5000 - val_mse: 3941527.5000 - val_mae: 1227.1884\n",
      "Epoch 81/100\n",
      "2980/2980 [==============================] - 8s 3ms/step - loss: 3963869.0000 - mse: 3963869.0000 - mae: 1235.8928 - val_loss: 3799854.5000 - val_mse: 3799854.5000 - val_mae: 1221.3291\n",
      "Epoch 82/100\n",
      "2980/2980 [==============================] - 8s 3ms/step - loss: 3956214.2500 - mse: 3956214.2500 - mae: 1235.8479 - val_loss: 3770771.2500 - val_mse: 3770771.2500 - val_mae: 1256.5199\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2980/2980 [==============================] - 9s 3ms/step - loss: 3948235.7500 - mse: 3948235.7500 - mae: 1234.3481 - val_loss: 3757209.7500 - val_mse: 3757209.7500 - val_mae: 1233.2015\n",
      "Epoch 84/100\n",
      "2980/2980 [==============================] - 7s 3ms/step - loss: 3944232.2500 - mse: 3944232.2500 - mae: 1234.5404 - val_loss: 3762858.0000 - val_mse: 3762858.0000 - val_mae: 1222.9717\n",
      "Epoch 85/100\n",
      "2980/2980 [==============================] - 8s 3ms/step - loss: 3943947.2500 - mse: 3943947.2500 - mae: 1231.7017 - val_loss: 3826620.2500 - val_mse: 3826620.2500 - val_mae: 1219.3035\n",
      "Epoch 86/100\n",
      "2980/2980 [==============================] - 9s 3ms/step - loss: 3936719.2500 - mse: 3936719.2500 - mae: 1231.4930 - val_loss: 3778468.5000 - val_mse: 3778468.5000 - val_mae: 1212.2037\n",
      "Epoch 87/100\n",
      "2980/2980 [==============================] - 8s 3ms/step - loss: 3950250.2500 - mse: 3950250.2500 - mae: 1232.2272 - val_loss: 4116233.2500 - val_mse: 4116233.2500 - val_mae: 1230.8459\n",
      "Epoch 88/100\n",
      "2980/2980 [==============================] - 8s 3ms/step - loss: 3951198.0000 - mse: 3951198.0000 - mae: 1234.3633 - val_loss: 4219987.5000 - val_mse: 4219987.5000 - val_mae: 1414.7085\n",
      "Epoch 89/100\n",
      "2980/2980 [==============================] - 8s 3ms/step - loss: 3920546.5000 - mse: 3920546.5000 - mae: 1233.5110 - val_loss: 3833136.2500 - val_mse: 3833136.2500 - val_mae: 1213.4524\n",
      "Epoch 90/100\n",
      "2980/2980 [==============================] - 8s 3ms/step - loss: 3939253.2500 - mse: 3939253.2500 - mae: 1233.3505 - val_loss: 3953113.2500 - val_mse: 3953113.2500 - val_mae: 1226.2599\n",
      "Epoch 91/100\n",
      "2980/2980 [==============================] - 7s 2ms/step - loss: 3921399.2500 - mse: 3921399.2500 - mae: 1233.3820 - val_loss: 3868064.2500 - val_mse: 3868064.2500 - val_mae: 1275.9921\n",
      "Epoch 92/100\n",
      "2980/2980 [==============================] - 10s 3ms/step - loss: 3921370.7500 - mse: 3921370.7500 - mae: 1233.0688 - val_loss: 3729191.5000 - val_mse: 3729191.5000 - val_mae: 1234.2645\n",
      "Epoch 93/100\n",
      "2980/2980 [==============================] - 9s 3ms/step - loss: 3915136.2500 - mse: 3915136.2500 - mae: 1234.0486 - val_loss: 3923972.7500 - val_mse: 3923972.7500 - val_mae: 1227.9451\n",
      "Epoch 94/100\n",
      "2980/2980 [==============================] - 8s 3ms/step - loss: 3914235.7500 - mse: 3914235.7500 - mae: 1229.7300 - val_loss: 4255869.0000 - val_mse: 4255869.0000 - val_mae: 1249.2008\n",
      "Epoch 95/100\n",
      "2980/2980 [==============================] - 7s 2ms/step - loss: 3907413.5000 - mse: 3907413.5000 - mae: 1229.5710 - val_loss: 3854545.2500 - val_mse: 3854545.2500 - val_mae: 1350.2657\n",
      "Epoch 96/100\n",
      "2980/2980 [==============================] - 8s 3ms/step - loss: 3902117.0000 - mse: 3902117.0000 - mae: 1230.5540 - val_loss: 3750850.2500 - val_mse: 3750850.2500 - val_mae: 1226.8297\n",
      "Epoch 97/100\n",
      "2980/2980 [==============================] - 10s 3ms/step - loss: 3914660.5000 - mse: 3914660.5000 - mae: 1228.8917 - val_loss: 4814305.0000 - val_mse: 4814305.0000 - val_mae: 1322.2894\n",
      "Epoch 98/100\n",
      "2980/2980 [==============================] - 8s 3ms/step - loss: 3903196.0000 - mse: 3903196.0000 - mae: 1229.3153 - val_loss: 3711726.5000 - val_mse: 3711726.5000 - val_mae: 1235.3193\n",
      "Epoch 99/100\n",
      "2980/2980 [==============================] - 8s 3ms/step - loss: 3898109.0000 - mse: 3898109.0000 - mae: 1229.8755 - val_loss: 3746892.2500 - val_mse: 3746892.2500 - val_mae: 1237.1818\n",
      "Epoch 100/100\n",
      "2980/2980 [==============================] - 7s 2ms/step - loss: 3885363.7500 - mse: 3885363.7500 - mae: 1227.5720 - val_loss: 3988240.0000 - val_mse: 3988240.0000 - val_mae: 1347.0333\n",
      "Wall time: 13min 49s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "init_epochs = 0\n",
    "epochs_now = 100\n",
    "history = model.fit(X_train, y_train, epochs=epochs_now, validation_data=(X_val, y_val), initial_epoch=init_epochs)\n",
    "mse_history += history.history['mse']\n",
    "mae_history += history.history['mae']\n",
    "model.save(f'linear_4/model_{epochs_now}.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 101/500\n",
      "2980/2980 [==============================] - 8s 3ms/step - loss: 3915278.2500 - mse: 3915278.2500 - mae: 1229.1018 - val_loss: 3749320.5000 - val_mse: 3749320.5000 - val_mae: 1226.3833\n",
      "Epoch 102/500\n",
      "2980/2980 [==============================] - 8s 3ms/step - loss: 3872621.7500 - mse: 3872621.7500 - mae: 1228.9949 - val_loss: 3751294.2500 - val_mse: 3751294.2500 - val_mae: 1264.8848\n",
      "Epoch 103/500\n",
      "2980/2980 [==============================] - 8s 3ms/step - loss: 3900788.5000 - mse: 3900788.5000 - mae: 1229.4510 - val_loss: 3967374.7500 - val_mse: 3967374.7500 - val_mae: 1287.9169\n",
      "Epoch 104/500\n",
      "2980/2980 [==============================] - 8s 3ms/step - loss: 3890459.2500 - mse: 3890459.2500 - mae: 1228.4453 - val_loss: 3717576.0000 - val_mse: 3717576.0000 - val_mae: 1222.1578\n",
      "Epoch 105/500\n",
      "2980/2980 [==============================] - 9s 3ms/step - loss: 3892767.2500 - mse: 3892767.2500 - mae: 1228.7207 - val_loss: 4053567.7500 - val_mse: 4053567.7500 - val_mae: 1378.5249\n",
      "Epoch 106/500\n",
      "2980/2980 [==============================] - 8s 3ms/step - loss: 3882926.7500 - mse: 3882926.7500 - mae: 1227.0973 - val_loss: 3756278.0000 - val_mse: 3756278.0000 - val_mae: 1235.7651\n",
      "Epoch 107/500\n",
      "2980/2980 [==============================] - 8s 3ms/step - loss: 3893467.0000 - mse: 3893467.0000 - mae: 1228.8977 - val_loss: 3919989.5000 - val_mse: 3919989.5000 - val_mae: 1362.5110\n",
      "Epoch 108/500\n",
      "2980/2980 [==============================] - 8s 3ms/step - loss: 3895990.5000 - mse: 3895990.5000 - mae: 1228.7620 - val_loss: 4108319.0000 - val_mse: 4108319.0000 - val_mae: 1233.3486\n",
      "Epoch 109/500\n",
      "2980/2980 [==============================] - 7s 2ms/step - loss: 3883159.5000 - mse: 3883159.5000 - mae: 1228.4178 - val_loss: 3756820.5000 - val_mse: 3756820.5000 - val_mae: 1284.7421\n",
      "Epoch 110/500\n",
      "2980/2980 [==============================] - 8s 3ms/step - loss: 3898719.7500 - mse: 3898719.7500 - mae: 1227.6376 - val_loss: 3803460.7500 - val_mse: 3803460.7500 - val_mae: 1225.8438\n",
      "Epoch 111/500\n",
      "2980/2980 [==============================] - 8s 3ms/step - loss: 3860809.0000 - mse: 3860809.0000 - mae: 1226.2214 - val_loss: 3956441.0000 - val_mse: 3956441.0000 - val_mae: 1233.3125\n",
      "Epoch 112/500\n",
      "2980/2980 [==============================] - 8s 3ms/step - loss: 3878870.2500 - mse: 3878870.2500 - mae: 1226.6368 - val_loss: 3849087.7500 - val_mse: 3849087.7500 - val_mae: 1213.2998\n",
      "Epoch 113/500\n",
      "2980/2980 [==============================] - 8s 3ms/step - loss: 3883883.5000 - mse: 3883883.5000 - mae: 1229.5067 - val_loss: 3808843.0000 - val_mse: 3808843.0000 - val_mae: 1255.7936\n",
      "Epoch 114/500\n",
      "2980/2980 [==============================] - 7s 3ms/step - loss: 3894053.0000 - mse: 3894053.0000 - mae: 1228.4943 - val_loss: 3740637.7500 - val_mse: 3740637.7500 - val_mae: 1232.2327\n",
      "Epoch 115/500\n",
      "2980/2980 [==============================] - 8s 3ms/step - loss: 3869350.0000 - mse: 3869350.0000 - mae: 1228.9442 - val_loss: 3758455.2500 - val_mse: 3758455.2500 - val_mae: 1228.6097\n",
      "Epoch 116/500\n",
      "2980/2980 [==============================] - 8s 3ms/step - loss: 3859016.0000 - mse: 3859016.0000 - mae: 1226.1547 - val_loss: 3783435.5000 - val_mse: 3783435.5000 - val_mae: 1239.6504\n",
      "Epoch 117/500\n",
      "2980/2980 [==============================] - 7s 2ms/step - loss: 3874164.7500 - mse: 3874164.7500 - mae: 1225.2091 - val_loss: 3783605.2500 - val_mse: 3783605.2500 - val_mae: 1229.1998\n",
      "Epoch 118/500\n",
      "2980/2980 [==============================] - 5s 2ms/step - loss: 3876587.2500 - mse: 3876587.2500 - mae: 1227.3677 - val_loss: 3837436.2500 - val_mse: 3837436.2500 - val_mae: 1295.5325\n",
      "Epoch 119/500\n",
      "2980/2980 [==============================] - 2836s 952ms/step - loss: 3854698.7500 - mse: 3854698.7500 - mae: 1225.5857 - val_loss: 3701018.7500 - val_mse: 3701018.7500 - val_mae: 1253.6501\n",
      "Epoch 120/500\n",
      "2980/2980 [==============================] - 8s 3ms/step - loss: 3875622.5000 - mse: 3875622.5000 - mae: 1227.3876 - val_loss: 3770774.2500 - val_mse: 3770774.2500 - val_mae: 1217.2848\n",
      "Epoch 121/500\n",
      "2980/2980 [==============================] - 7s 2ms/step - loss: 3859840.5000 - mse: 3859840.5000 - mae: 1225.4200 - val_loss: 3816867.7500 - val_mse: 3816867.7500 - val_mae: 1214.7179\n",
      "Epoch 122/500\n",
      "2980/2980 [==============================] - 5s 2ms/step - loss: 3861321.7500 - mse: 3861321.7500 - mae: 1223.2910 - val_loss: 4032901.5000 - val_mse: 4032901.5000 - val_mae: 1223.4713\n",
      "Epoch 123/500\n",
      "2980/2980 [==============================] - 3s 986us/step - loss: 3852071.7500 - mse: 3852071.7500 - mae: 1223.8726 - val_loss: 3748992.0000 - val_mse: 3748992.0000 - val_mae: 1288.8718\n",
      "Epoch 124/500\n",
      "2980/2980 [==============================] - 4s 1ms/step - loss: 3857161.5000 - mse: 3857161.5000 - mae: 1222.3353 - val_loss: 4019389.7500 - val_mse: 4019389.7500 - val_mae: 1305.2860\n",
      "Epoch 125/500\n",
      "2980/2980 [==============================] - 3s 953us/step - loss: 3866458.2500 - mse: 3866458.2500 - mae: 1221.9211 - val_loss: 3761852.2500 - val_mse: 3761852.2500 - val_mae: 1291.4424\n",
      "Epoch 126/500\n",
      "2980/2980 [==============================] - 3s 1ms/step - loss: 3840692.7500 - mse: 3840692.7500 - mae: 1222.6589 - val_loss: 3756157.2500 - val_mse: 3756157.2500 - val_mae: 1236.5186\n",
      "Epoch 127/500\n",
      "2980/2980 [==============================] - 3s 1ms/step - loss: 3853191.0000 - mse: 3853191.0000 - mae: 1219.6781 - val_loss: 3884311.7500 - val_mse: 3884311.7500 - val_mae: 1212.0309\n",
      "Epoch 128/500\n",
      "2980/2980 [==============================] - 3s 984us/step - loss: 3841908.5000 - mse: 3841908.5000 - mae: 1222.8181 - val_loss: 3677656.7500 - val_mse: 3677656.7500 - val_mae: 1237.5995\n",
      "Epoch 129/500\n",
      "2980/2980 [==============================] - 3s 916us/step - loss: 3834067.0000 - mse: 3834067.0000 - mae: 1222.0400 - val_loss: 3827879.5000 - val_mse: 3827879.5000 - val_mae: 1310.8596\n",
      "Epoch 130/500\n",
      "2980/2980 [==============================] - 3s 914us/step - loss: 3839153.2500 - mse: 3839153.2500 - mae: 1223.5682 - val_loss: 3898614.2500 - val_mse: 3898614.2500 - val_mae: 1343.4886\n",
      "Epoch 131/500\n",
      "2980/2980 [==============================] - 4s 1ms/step - loss: 3821708.0000 - mse: 3821708.0000 - mae: 1222.7036 - val_loss: 3724628.0000 - val_mse: 3724628.0000 - val_mae: 1285.7338\n",
      "Epoch 132/500\n",
      "2980/2980 [==============================] - 5s 2ms/step - loss: 3860080.0000 - mse: 3860080.0000 - mae: 1221.9379 - val_loss: 3762355.0000 - val_mse: 3762355.0000 - val_mae: 1209.7789\n",
      "Epoch 133/500\n",
      "2980/2980 [==============================] - 4s 1ms/step - loss: 3842464.7500 - mse: 3842464.7500 - mae: 1221.7308 - val_loss: 3734281.7500 - val_mse: 3734281.7500 - val_mae: 1273.6084\n",
      "Epoch 134/500\n",
      "2980/2980 [==============================] - 3s 1ms/step - loss: 3841374.5000 - mse: 3841374.5000 - mae: 1220.4203 - val_loss: 4157405.0000 - val_mse: 4157405.0000 - val_mae: 1241.1998\n",
      "Epoch 135/500\n",
      "2980/2980 [==============================] - 4s 1ms/step - loss: 3843657.0000 - mse: 3843657.0000 - mae: 1220.5464 - val_loss: 3760064.0000 - val_mse: 3760064.0000 - val_mae: 1308.5276\n",
      "Epoch 136/500\n",
      "2980/2980 [==============================] - 3s 1ms/step - loss: 3834790.2500 - mse: 3834790.2500 - mae: 1219.3308 - val_loss: 3775510.2500 - val_mse: 3775510.2500 - val_mae: 1247.5657\n",
      "Epoch 137/500\n",
      "2980/2980 [==============================] - 3s 1ms/step - loss: 3846848.0000 - mse: 3846848.0000 - mae: 1220.8943 - val_loss: 3941494.7500 - val_mse: 3941494.7500 - val_mae: 1407.3370\n",
      "Epoch 138/500\n",
      "2980/2980 [==============================] - 3s 1ms/step - loss: 3814393.5000 - mse: 3814393.5000 - mae: 1219.5547 - val_loss: 3733869.2500 - val_mse: 3733869.2500 - val_mae: 1244.1389\n",
      "Epoch 139/500\n",
      "2980/2980 [==============================] - 3s 1ms/step - loss: 3827737.2500 - mse: 3827737.2500 - mae: 1219.7058 - val_loss: 3793261.2500 - val_mse: 3793261.2500 - val_mae: 1238.2322\n",
      "Epoch 140/500\n",
      "2980/2980 [==============================] - 3s 946us/step - loss: 3836883.5000 - mse: 3836883.5000 - mae: 1220.5729 - val_loss: 3791208.5000 - val_mse: 3791208.5000 - val_mae: 1210.9703\n",
      "Epoch 141/500\n",
      "2980/2980 [==============================] - 3s 951us/step - loss: 3808385.0000 - mse: 3808385.0000 - mae: 1217.9382 - val_loss: 3746940.0000 - val_mse: 3746940.0000 - val_mae: 1249.6257\n",
      "Epoch 142/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2980/2980 [==============================] - 3s 934us/step - loss: 3803209.5000 - mse: 3803209.5000 - mae: 1219.2833 - val_loss: 3925888.0000 - val_mse: 3925888.0000 - val_mae: 1269.0256\n",
      "Epoch 143/500\n",
      "2980/2980 [==============================] - 3s 951us/step - loss: 3824146.0000 - mse: 3824146.0000 - mae: 1219.3866 - val_loss: 4106837.5000 - val_mse: 4106837.5000 - val_mae: 1341.3149\n",
      "Epoch 144/500\n",
      "2980/2980 [==============================] - 3s 969us/step - loss: 3798316.7500 - mse: 3798316.7500 - mae: 1218.5997 - val_loss: 3771958.7500 - val_mse: 3771958.7500 - val_mae: 1216.4309\n",
      "Epoch 145/500\n",
      "2980/2980 [==============================] - 12s 4ms/step - loss: 3799774.7500 - mse: 3799774.7500 - mae: 1218.5906 - val_loss: 3702869.5000 - val_mse: 3702869.5000 - val_mae: 1248.1348\n",
      "Epoch 146/500\n",
      "2980/2980 [==============================] - 14s 5ms/step - loss: 3789478.0000 - mse: 3789478.0000 - mae: 1217.4138 - val_loss: 3733809.0000 - val_mse: 3733809.0000 - val_mae: 1220.6669\n",
      "Epoch 147/500\n",
      "2980/2980 [==============================] - 11s 4ms/step - loss: 3801974.5000 - mse: 3801974.5000 - mae: 1217.1592 - val_loss: 3753647.2500 - val_mse: 3753647.2500 - val_mae: 1240.8441\n",
      "Epoch 148/500\n",
      "2980/2980 [==============================] - 17s 6ms/step - loss: 3807628.5000 - mse: 3807628.5000 - mae: 1215.9884 - val_loss: 3766894.7500 - val_mse: 3766894.7500 - val_mae: 1280.7399\n",
      "Epoch 149/500\n",
      "2980/2980 [==============================] - 11s 4ms/step - loss: 3791495.0000 - mse: 3791495.0000 - mae: 1216.7554 - val_loss: 3707735.5000 - val_mse: 3707735.5000 - val_mae: 1245.2491\n",
      "Epoch 150/500\n",
      "2980/2980 [==============================] - 12s 4ms/step - loss: 3797666.2500 - mse: 3797666.2500 - mae: 1216.2063 - val_loss: 3876148.7500 - val_mse: 3876148.7500 - val_mae: 1284.4353\n",
      "Epoch 151/500\n",
      "2980/2980 [==============================] - 14s 5ms/step - loss: 3780378.5000 - mse: 3780378.5000 - mae: 1215.9628 - val_loss: 3869773.0000 - val_mse: 3869773.0000 - val_mae: 1320.0858\n",
      "Epoch 152/500\n",
      "2980/2980 [==============================] - 15s 5ms/step - loss: 3782520.5000 - mse: 3782520.5000 - mae: 1215.7584 - val_loss: 3862934.7500 - val_mse: 3862934.7500 - val_mae: 1321.0397\n",
      "Epoch 153/500\n",
      "2980/2980 [==============================] - 12s 4ms/step - loss: 3790074.7500 - mse: 3790074.7500 - mae: 1216.6803 - val_loss: 3882923.7500 - val_mse: 3882923.7500 - val_mae: 1288.4149\n",
      "Epoch 154/500\n",
      "2980/2980 [==============================] - 8s 3ms/step - loss: 3777865.7500 - mse: 3777865.7500 - mae: 1214.7379 - val_loss: 3780552.7500 - val_mse: 3780552.7500 - val_mae: 1263.2539\n",
      "Epoch 155/500\n",
      "2980/2980 [==============================] - 8s 3ms/step - loss: 3794267.2500 - mse: 3794267.2500 - mae: 1217.3782 - val_loss: 4005330.2500 - val_mse: 4005330.2500 - val_mae: 1267.3750\n",
      "Epoch 156/500\n",
      "2980/2980 [==============================] - 8s 3ms/step - loss: 3785596.7500 - mse: 3785596.7500 - mae: 1212.7032 - val_loss: 4103306.7500 - val_mse: 4103306.7500 - val_mae: 1229.3862\n",
      "Epoch 157/500\n",
      "2980/2980 [==============================] - 8s 3ms/step - loss: 3794906.0000 - mse: 3794906.0000 - mae: 1213.9301 - val_loss: 3746998.7500 - val_mse: 3746998.7500 - val_mae: 1229.8762\n",
      "Epoch 158/500\n",
      "2980/2980 [==============================] - 9s 3ms/step - loss: 3786141.2500 - mse: 3786141.2500 - mae: 1214.0186 - val_loss: 3828788.7500 - val_mse: 3828788.7500 - val_mae: 1219.9448\n",
      "Epoch 159/500\n",
      "2980/2980 [==============================] - 9s 3ms/step - loss: 3781679.5000 - mse: 3781679.5000 - mae: 1213.8240 - val_loss: 3841232.5000 - val_mse: 3841232.5000 - val_mae: 1223.3232\n",
      "Epoch 160/500\n",
      "2980/2980 [==============================] - 14s 5ms/step - loss: 3757322.2500 - mse: 3757322.2500 - mae: 1213.3933 - val_loss: 3715815.2500 - val_mse: 3715815.2500 - val_mae: 1224.6489\n",
      "Epoch 161/500\n",
      "2980/2980 [==============================] - 14s 5ms/step - loss: 3764922.5000 - mse: 3764922.5000 - mae: 1213.1093 - val_loss: 4045361.0000 - val_mse: 4045361.0000 - val_mae: 1225.3190\n",
      "Epoch 162/500\n",
      "2980/2980 [==============================] - 15s 5ms/step - loss: 3758743.7500 - mse: 3758743.7500 - mae: 1212.7250 - val_loss: 3827761.5000 - val_mse: 3827761.5000 - val_mae: 1221.5660\n",
      "Epoch 163/500\n",
      "2980/2980 [==============================] - 12s 4ms/step - loss: 3747938.0000 - mse: 3747938.0000 - mae: 1211.2197 - val_loss: 3959824.0000 - val_mse: 3959824.0000 - val_mae: 1213.8082\n",
      "Epoch 164/500\n",
      "2980/2980 [==============================] - 9s 3ms/step - loss: 3750103.2500 - mse: 3750103.2500 - mae: 1211.2751 - val_loss: 3845750.7500 - val_mse: 3845750.7500 - val_mae: 1217.2289\n",
      "Epoch 165/500\n",
      "2980/2980 [==============================] - 9s 3ms/step - loss: 3777850.2500 - mse: 3777850.2500 - mae: 1212.6022 - val_loss: 3760768.7500 - val_mse: 3760768.7500 - val_mae: 1247.8613\n",
      "Epoch 166/500\n",
      "2980/2980 [==============================] - 10s 3ms/step - loss: 3747565.2500 - mse: 3747565.2500 - mae: 1210.6895 - val_loss: 3741119.2500 - val_mse: 3741119.2500 - val_mae: 1239.0253\n",
      "Epoch 167/500\n",
      "2980/2980 [==============================] - 11s 4ms/step - loss: 3754525.0000 - mse: 3754525.0000 - mae: 1210.0679 - val_loss: 3803070.5000 - val_mse: 3803070.5000 - val_mae: 1274.8125\n",
      "Epoch 168/500\n",
      "2980/2980 [==============================] - 11s 4ms/step - loss: 3774697.2500 - mse: 3774697.2500 - mae: 1211.5323 - val_loss: 3803679.0000 - val_mse: 3803679.0000 - val_mae: 1247.2731\n",
      "Epoch 169/500\n",
      "2980/2980 [==============================] - 13s 4ms/step - loss: 3776428.2500 - mse: 3776428.2500 - mae: 1211.6615 - val_loss: 4006650.5000 - val_mse: 4006650.5000 - val_mae: 1225.6102\n",
      "Epoch 170/500\n",
      "2980/2980 [==============================] - 11s 4ms/step - loss: 3747904.7500 - mse: 3747904.7500 - mae: 1209.9625 - val_loss: 3986721.0000 - val_mse: 3986721.0000 - val_mae: 1296.2821\n",
      "Epoch 171/500\n",
      "2980/2980 [==============================] - 14s 5ms/step - loss: 3742613.0000 - mse: 3742613.0000 - mae: 1209.8467 - val_loss: 3773515.7500 - val_mse: 3773515.7500 - val_mae: 1280.4026\n",
      "Epoch 172/500\n",
      "2980/2980 [==============================] - 14s 5ms/step - loss: 3741728.2500 - mse: 3741728.2500 - mae: 1209.4664 - val_loss: 3777022.0000 - val_mse: 3777022.0000 - val_mae: 1234.8290\n",
      "Epoch 173/500\n",
      "2980/2980 [==============================] - 14s 5ms/step - loss: 3733954.5000 - mse: 3733954.5000 - mae: 1208.7084 - val_loss: 3781052.2500 - val_mse: 3781052.2500 - val_mae: 1234.4701\n",
      "Epoch 174/500\n",
      "2980/2980 [==============================] - 15s 5ms/step - loss: 3729939.5000 - mse: 3729939.5000 - mae: 1210.7114 - val_loss: 3735442.5000 - val_mse: 3735442.5000 - val_mae: 1284.1212\n",
      "Epoch 175/500\n",
      "2980/2980 [==============================] - 14s 5ms/step - loss: 3752028.2500 - mse: 3752028.2500 - mae: 1210.0839 - val_loss: 3940205.7500 - val_mse: 3940205.7500 - val_mae: 1322.7651\n",
      "Epoch 176/500\n",
      "2980/2980 [==============================] - 14s 5ms/step - loss: 3735346.0000 - mse: 3735346.0000 - mae: 1210.0111 - val_loss: 3989641.0000 - val_mse: 3989641.0000 - val_mae: 1238.9459\n",
      "Epoch 177/500\n",
      "2980/2980 [==============================] - 14s 5ms/step - loss: 3738907.7500 - mse: 3738907.7500 - mae: 1207.4772 - val_loss: 3852619.7500 - val_mse: 3852619.7500 - val_mae: 1320.6625\n",
      "Epoch 178/500\n",
      "2980/2980 [==============================] - 14s 5ms/step - loss: 3748393.5000 - mse: 3748393.5000 - mae: 1209.4829 - val_loss: 3840083.2500 - val_mse: 3840083.2500 - val_mae: 1336.6074\n",
      "Epoch 179/500\n",
      "2980/2980 [==============================] - 15s 5ms/step - loss: 3731964.0000 - mse: 3731964.0000 - mae: 1207.8347 - val_loss: 3815319.7500 - val_mse: 3815319.7500 - val_mae: 1239.1710\n",
      "Epoch 180/500\n",
      "2980/2980 [==============================] - 14s 5ms/step - loss: 3734831.5000 - mse: 3734831.5000 - mae: 1206.3895 - val_loss: 3921539.2500 - val_mse: 3921539.2500 - val_mae: 1380.3722\n",
      "Epoch 181/500\n",
      "2980/2980 [==============================] - 15s 5ms/step - loss: 3730902.0000 - mse: 3730902.0000 - mae: 1207.6494 - val_loss: 3755362.5000 - val_mse: 3755362.5000 - val_mae: 1237.8677\n",
      "Epoch 182/500\n",
      "2980/2980 [==============================] - 13s 4ms/step - loss: 3744602.0000 - mse: 3744602.0000 - mae: 1205.3840 - val_loss: 4007284.0000 - val_mse: 4007284.0000 - val_mae: 1355.2955\n",
      "Epoch 183/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2980/2980 [==============================] - 14s 5ms/step - loss: 3727526.5000 - mse: 3727526.5000 - mae: 1207.7883 - val_loss: 3738064.7500 - val_mse: 3738064.7500 - val_mae: 1248.3442\n",
      "Epoch 184/500\n",
      "2980/2980 [==============================] - 15s 5ms/step - loss: 3724247.0000 - mse: 3724247.0000 - mae: 1206.2305 - val_loss: 3839479.7500 - val_mse: 3839479.7500 - val_mae: 1264.7943\n",
      "Epoch 185/500\n",
      "2980/2980 [==============================] - 14s 5ms/step - loss: 3707744.5000 - mse: 3707744.5000 - mae: 1207.0259 - val_loss: 3780394.0000 - val_mse: 3780394.0000 - val_mae: 1246.9813\n",
      "Epoch 186/500\n",
      "2980/2980 [==============================] - 14s 5ms/step - loss: 3724455.5000 - mse: 3724455.5000 - mae: 1204.4885 - val_loss: 3907863.5000 - val_mse: 3907863.5000 - val_mae: 1244.7039\n",
      "Epoch 187/500\n",
      "2980/2980 [==============================] - 15s 5ms/step - loss: 3722041.0000 - mse: 3722041.0000 - mae: 1206.6836 - val_loss: 3907777.7500 - val_mse: 3907777.7500 - val_mae: 1228.2965\n",
      "Epoch 188/500\n",
      "2980/2980 [==============================] - 12s 4ms/step - loss: 3725062.5000 - mse: 3725062.5000 - mae: 1205.2433 - val_loss: 3919798.2500 - val_mse: 3919798.2500 - val_mae: 1321.5737\n",
      "Epoch 189/500\n",
      "2980/2980 [==============================] - 12s 4ms/step - loss: 3710708.0000 - mse: 3710708.0000 - mae: 1204.9171 - val_loss: 3801788.2500 - val_mse: 3801788.2500 - val_mae: 1273.1597\n",
      "Epoch 190/500\n",
      "2980/2980 [==============================] - 12s 4ms/step - loss: 3719962.2500 - mse: 3719962.2500 - mae: 1204.3510 - val_loss: 3823532.5000 - val_mse: 3823532.5000 - val_mae: 1265.3567\n",
      "Epoch 191/500\n",
      "2980/2980 [==============================] - 14s 5ms/step - loss: 3709205.2500 - mse: 3709205.2500 - mae: 1202.2610 - val_loss: 3833142.0000 - val_mse: 3833142.0000 - val_mae: 1268.2385\n",
      "Epoch 192/500\n",
      "2980/2980 [==============================] - 12s 4ms/step - loss: 3706007.7500 - mse: 3706007.7500 - mae: 1205.1357 - val_loss: 3771396.5000 - val_mse: 3771396.5000 - val_mae: 1257.7877\n",
      "Epoch 193/500\n",
      "2980/2980 [==============================] - 14s 5ms/step - loss: 3692816.0000 - mse: 3692816.0000 - mae: 1203.9659 - val_loss: 3834159.2500 - val_mse: 3834159.2500 - val_mae: 1240.3519\n",
      "Epoch 194/500\n",
      "2980/2980 [==============================] - 14s 5ms/step - loss: 3709649.7500 - mse: 3709649.7500 - mae: 1205.1484 - val_loss: 4008702.2500 - val_mse: 4008702.2500 - val_mae: 1247.8185\n",
      "Epoch 195/500\n",
      "2980/2980 [==============================] - 11s 4ms/step - loss: 3714759.7500 - mse: 3714759.7500 - mae: 1205.4006 - val_loss: 3803194.7500 - val_mse: 3803194.7500 - val_mae: 1284.7625\n",
      "Epoch 196/500\n",
      "2980/2980 [==============================] - 13s 4ms/step - loss: 3690647.7500 - mse: 3690647.7500 - mae: 1203.6066 - val_loss: 3892343.7500 - val_mse: 3892343.7500 - val_mae: 1222.6986\n",
      "Epoch 197/500\n",
      "2980/2980 [==============================] - 15s 5ms/step - loss: 3696795.5000 - mse: 3696795.5000 - mae: 1204.0812 - val_loss: 3845037.5000 - val_mse: 3845037.5000 - val_mae: 1217.9248\n",
      "Epoch 198/500\n",
      "2980/2980 [==============================] - 15s 5ms/step - loss: 3711752.2500 - mse: 3711752.2500 - mae: 1202.3046 - val_loss: 3859173.5000 - val_mse: 3859173.5000 - val_mae: 1222.3645\n",
      "Epoch 199/500\n",
      "2980/2980 [==============================] - 13s 4ms/step - loss: 3692476.0000 - mse: 3692476.0000 - mae: 1202.5494 - val_loss: 4009528.0000 - val_mse: 4009528.0000 - val_mae: 1361.2490\n",
      "Epoch 200/500\n",
      "2980/2980 [==============================] - 15s 5ms/step - loss: 3699811.2500 - mse: 3699811.2500 - mae: 1202.4385 - val_loss: 3844770.5000 - val_mse: 3844770.5000 - val_mae: 1225.5498\n",
      "Epoch 201/500\n",
      "2980/2980 [==============================] - 11s 4ms/step - loss: 3681764.7500 - mse: 3681764.7500 - mae: 1200.9784 - val_loss: 3867888.0000 - val_mse: 3867888.0000 - val_mae: 1301.8418\n",
      "Epoch 202/500\n",
      "2980/2980 [==============================] - 15s 5ms/step - loss: 3648055.0000 - mse: 3648055.0000 - mae: 1200.1263 - val_loss: 3772495.7500 - val_mse: 3772495.7500 - val_mae: 1239.9972\n",
      "Epoch 203/500\n",
      "2980/2980 [==============================] - 14s 5ms/step - loss: 3652478.2500 - mse: 3652478.2500 - mae: 1200.7086 - val_loss: 3902558.2500 - val_mse: 3902558.2500 - val_mae: 1222.2655\n",
      "Epoch 204/500\n",
      "2980/2980 [==============================] - 13s 4ms/step - loss: 3680384.2500 - mse: 3680384.2500 - mae: 1201.0829 - val_loss: 4088340.0000 - val_mse: 4088340.0000 - val_mae: 1325.7793\n",
      "Epoch 205/500\n",
      "2980/2980 [==============================] - 13s 4ms/step - loss: 3664120.0000 - mse: 3664120.0000 - mae: 1201.3804 - val_loss: 3797581.7500 - val_mse: 3797581.7500 - val_mae: 1315.0348\n",
      "Epoch 206/500\n",
      "2980/2980 [==============================] - 13s 4ms/step - loss: 3648457.5000 - mse: 3648457.5000 - mae: 1201.9116 - val_loss: 4042261.2500 - val_mse: 4042261.2500 - val_mae: 1230.4877\n",
      "Epoch 207/500\n",
      "2980/2980 [==============================] - 14s 5ms/step - loss: 3659747.5000 - mse: 3659747.5000 - mae: 1199.7198 - val_loss: 3866442.7500 - val_mse: 3866442.7500 - val_mae: 1270.6954\n",
      "Epoch 208/500\n",
      "2980/2980 [==============================] - 13s 4ms/step - loss: 3666258.7500 - mse: 3666258.7500 - mae: 1201.7347 - val_loss: 3958191.2500 - val_mse: 3958191.2500 - val_mae: 1337.5959\n",
      "Epoch 209/500\n",
      "2980/2980 [==============================] - 11s 4ms/step - loss: 3651805.7500 - mse: 3651805.7500 - mae: 1199.3965 - val_loss: 3897612.2500 - val_mse: 3897612.2500 - val_mae: 1233.9027\n",
      "Epoch 210/500\n",
      "2980/2980 [==============================] - 9s 3ms/step - loss: 3664921.5000 - mse: 3664921.5000 - mae: 1201.2582 - val_loss: 3805681.7500 - val_mse: 3805681.7500 - val_mae: 1230.5812\n",
      "Epoch 211/500\n",
      "2980/2980 [==============================] - 9s 3ms/step - loss: 3653971.5000 - mse: 3653971.5000 - mae: 1199.7443 - val_loss: 3831910.2500 - val_mse: 3831910.2500 - val_mae: 1293.4154\n",
      "Epoch 212/500\n",
      "2980/2980 [==============================] - 12s 4ms/step - loss: 3635205.0000 - mse: 3635205.0000 - mae: 1199.2012 - val_loss: 3930222.0000 - val_mse: 3930222.0000 - val_mae: 1301.4752\n",
      "Epoch 213/500\n",
      "2980/2980 [==============================] - 13s 4ms/step - loss: 3645685.2500 - mse: 3645685.2500 - mae: 1199.7926 - val_loss: 3960853.5000 - val_mse: 3960853.5000 - val_mae: 1324.0265\n",
      "Epoch 214/500\n",
      "2980/2980 [==============================] - 13s 4ms/step - loss: 3659973.7500 - mse: 3659973.7500 - mae: 1199.2457 - val_loss: 3783601.7500 - val_mse: 3783601.7500 - val_mae: 1282.9642\n",
      "Epoch 215/500\n",
      "2980/2980 [==============================] - 13s 5ms/step - loss: 3641794.2500 - mse: 3641794.2500 - mae: 1199.8746 - val_loss: 3898079.5000 - val_mse: 3898079.5000 - val_mae: 1348.5297\n",
      "Epoch 216/500\n",
      "2980/2980 [==============================] - 10s 3ms/step - loss: 3642214.2500 - mse: 3642214.2500 - mae: 1198.5262 - val_loss: 3887595.7500 - val_mse: 3887595.7500 - val_mae: 1231.8302\n",
      "Epoch 217/500\n",
      "2980/2980 [==============================] - 11s 4ms/step - loss: 3638190.5000 - mse: 3638190.5000 - mae: 1199.5790 - val_loss: 4045903.2500 - val_mse: 4045903.2500 - val_mae: 1269.4816\n",
      "Epoch 218/500\n",
      "2980/2980 [==============================] - 11s 4ms/step - loss: 3615424.2500 - mse: 3615424.2500 - mae: 1196.5410 - val_loss: 4149568.2500 - val_mse: 4149568.2500 - val_mae: 1371.4105\n",
      "Epoch 219/500\n",
      "2980/2980 [==============================] - 13s 4ms/step - loss: 3629422.7500 - mse: 3629422.7500 - mae: 1196.9611 - val_loss: 3811835.0000 - val_mse: 3811835.0000 - val_mae: 1243.7001\n",
      "Epoch 220/500\n",
      "2980/2980 [==============================] - 14s 5ms/step - loss: 3641469.7500 - mse: 3641469.7500 - mae: 1200.4739 - val_loss: 3983396.0000 - val_mse: 3983396.0000 - val_mae: 1339.6010\n",
      "Epoch 221/500\n",
      "2980/2980 [==============================] - 13s 4ms/step - loss: 3645718.5000 - mse: 3645718.5000 - mae: 1199.8739 - val_loss: 3825683.5000 - val_mse: 3825683.5000 - val_mae: 1302.9822\n",
      "Epoch 222/500\n",
      "2980/2980 [==============================] - 10s 3ms/step - loss: 3626736.2500 - mse: 3626736.2500 - mae: 1198.5074 - val_loss: 4002579.7500 - val_mse: 4002579.7500 - val_mae: 1350.3049\n",
      "Epoch 223/500\n",
      "2980/2980 [==============================] - 12s 4ms/step - loss: 3629578.2500 - mse: 3629578.2500 - mae: 1198.4755 - val_loss: 3888329.0000 - val_mse: 3888329.0000 - val_mae: 1335.9209\n",
      "Epoch 224/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2980/2980 [==============================] - 13s 4ms/step - loss: 3619888.7500 - mse: 3619888.7500 - mae: 1195.0663 - val_loss: 3905471.0000 - val_mse: 3905471.0000 - val_mae: 1274.5044\n",
      "Epoch 225/500\n",
      "2980/2980 [==============================] - 13s 4ms/step - loss: 3625390.5000 - mse: 3625390.5000 - mae: 1196.4236 - val_loss: 3757175.2500 - val_mse: 3757175.2500 - val_mae: 1251.7775\n",
      "Epoch 226/500\n",
      "2980/2980 [==============================] - 11s 4ms/step - loss: 3595805.0000 - mse: 3595805.0000 - mae: 1195.1417 - val_loss: 3800780.7500 - val_mse: 3800780.7500 - val_mae: 1265.9481\n",
      "Epoch 227/500\n",
      "2980/2980 [==============================] - 10s 3ms/step - loss: 3610222.5000 - mse: 3610222.5000 - mae: 1196.5677 - val_loss: 3858370.7500 - val_mse: 3858370.7500 - val_mae: 1243.6449\n",
      "Epoch 228/500\n",
      "2980/2980 [==============================] - 14s 5ms/step - loss: 3601960.0000 - mse: 3601960.0000 - mae: 1194.7374 - val_loss: 3822692.7500 - val_mse: 3822692.7500 - val_mae: 1220.7380\n",
      "Epoch 229/500\n",
      "2980/2980 [==============================] - 9s 3ms/step - loss: 3618249.2500 - mse: 3618249.2500 - mae: 1196.2421 - val_loss: 3943371.7500 - val_mse: 3943371.7500 - val_mae: 1244.9304\n",
      "Epoch 230/500\n",
      "2980/2980 [==============================] - 9s 3ms/step - loss: 3607951.5000 - mse: 3607951.5000 - mae: 1194.6996 - val_loss: 4037814.5000 - val_mse: 4037814.5000 - val_mae: 1226.3770\n",
      "Epoch 231/500\n",
      "2980/2980 [==============================] - 13s 4ms/step - loss: 3623560.5000 - mse: 3623560.5000 - mae: 1196.5431 - val_loss: 3802632.5000 - val_mse: 3802632.5000 - val_mae: 1277.6053\n",
      "Epoch 232/500\n",
      "2980/2980 [==============================] - 13s 4ms/step - loss: 3593549.2500 - mse: 3593549.2500 - mae: 1194.8716 - val_loss: 3862086.7500 - val_mse: 3862086.7500 - val_mae: 1293.7725\n",
      "Epoch 233/500\n",
      "2980/2980 [==============================] - 14s 5ms/step - loss: 3604021.5000 - mse: 3604021.5000 - mae: 1196.0364 - val_loss: 3849341.7500 - val_mse: 3849341.7500 - val_mae: 1240.3240\n",
      "Epoch 234/500\n",
      "2980/2980 [==============================] - 13s 5ms/step - loss: 3595482.0000 - mse: 3595482.0000 - mae: 1195.4390 - val_loss: 3792228.7500 - val_mse: 3792228.7500 - val_mae: 1225.3752\n",
      "Epoch 235/500\n",
      "2980/2980 [==============================] - 15s 5ms/step - loss: 3591391.0000 - mse: 3591391.0000 - mae: 1194.2738 - val_loss: 3858577.2500 - val_mse: 3858577.2500 - val_mae: 1232.9094\n",
      "Epoch 236/500\n",
      "2980/2980 [==============================] - 15s 5ms/step - loss: 3571588.2500 - mse: 3571588.2500 - mae: 1193.8290 - val_loss: 3977791.2500 - val_mse: 3977791.2500 - val_mae: 1223.5330\n",
      "Epoch 237/500\n",
      "2980/2980 [==============================] - 15s 5ms/step - loss: 3578207.7500 - mse: 3578207.7500 - mae: 1192.3353 - val_loss: 3908159.5000 - val_mse: 3908159.5000 - val_mae: 1249.5505\n",
      "Epoch 238/500\n",
      "2980/2980 [==============================] - 11s 4ms/step - loss: 3591705.2500 - mse: 3591705.2500 - mae: 1193.2290 - val_loss: 3982335.5000 - val_mse: 3982335.5000 - val_mae: 1346.0980\n",
      "Epoch 239/500\n",
      "2980/2980 [==============================] - 16s 5ms/step - loss: 3573887.2500 - mse: 3573887.2500 - mae: 1193.2225 - val_loss: 4070248.5000 - val_mse: 4070248.5000 - val_mae: 1237.8240\n",
      "Epoch 240/500\n",
      "2980/2980 [==============================] - 14s 5ms/step - loss: 3545078.0000 - mse: 3545078.0000 - mae: 1191.7793 - val_loss: 3822688.5000 - val_mse: 3822688.5000 - val_mae: 1247.1630\n",
      "Epoch 241/500\n",
      "2980/2980 [==============================] - 12s 4ms/step - loss: 3569605.7500 - mse: 3569605.7500 - mae: 1191.4928 - val_loss: 3806403.2500 - val_mse: 3806403.2500 - val_mae: 1242.0927\n",
      "Epoch 242/500\n",
      "2980/2980 [==============================] - 11s 4ms/step - loss: 3585114.5000 - mse: 3585114.5000 - mae: 1191.4081 - val_loss: 3896982.7500 - val_mse: 3896982.7500 - val_mae: 1220.2585\n",
      "Epoch 243/500\n",
      "2980/2980 [==============================] - 15s 5ms/step - loss: 3587553.0000 - mse: 3587553.0000 - mae: 1192.9658 - val_loss: 3938570.2500 - val_mse: 3938570.2500 - val_mae: 1305.9725\n",
      "Epoch 244/500\n",
      "2980/2980 [==============================] - 10s 3ms/step - loss: 3583986.5000 - mse: 3583986.5000 - mae: 1192.5137 - val_loss: 4163664.5000 - val_mse: 4163664.5000 - val_mae: 1238.8860\n",
      "Epoch 245/500\n",
      "2980/2980 [==============================] - 10s 3ms/step - loss: 3574201.2500 - mse: 3574201.2500 - mae: 1193.5557 - val_loss: 3777542.2500 - val_mse: 3777542.2500 - val_mae: 1244.5110\n",
      "Epoch 246/500\n",
      "2980/2980 [==============================] - 10s 3ms/step - loss: 3572709.0000 - mse: 3572709.0000 - mae: 1190.3005 - val_loss: 3958084.5000 - val_mse: 3958084.5000 - val_mae: 1279.1053\n",
      "Epoch 247/500\n",
      "2980/2980 [==============================] - 10s 3ms/step - loss: 3550997.2500 - mse: 3550997.2500 - mae: 1193.3511 - val_loss: 3839703.7500 - val_mse: 3839703.7500 - val_mae: 1299.6880\n",
      "Epoch 248/500\n",
      "2980/2980 [==============================] - 11s 4ms/step - loss: 3550876.0000 - mse: 3550876.0000 - mae: 1191.4501 - val_loss: 4099840.2500 - val_mse: 4099840.2500 - val_mae: 1372.8877\n",
      "Epoch 249/500\n",
      "2980/2980 [==============================] - 13s 4ms/step - loss: 3580259.5000 - mse: 3580259.5000 - mae: 1190.8363 - val_loss: 3933934.5000 - val_mse: 3933934.5000 - val_mae: 1226.9744\n",
      "Epoch 250/500\n",
      "2980/2980 [==============================] - 14s 5ms/step - loss: 3542410.7500 - mse: 3542410.7500 - mae: 1191.7397 - val_loss: 3982990.5000 - val_mse: 3982990.5000 - val_mae: 1393.8181\n",
      "Epoch 251/500\n",
      "2980/2980 [==============================] - 9s 3ms/step - loss: 3556800.2500 - mse: 3556800.2500 - mae: 1190.7328 - val_loss: 3862092.0000 - val_mse: 3862092.0000 - val_mae: 1233.3721\n",
      "Epoch 252/500\n",
      "2980/2980 [==============================] - 8s 3ms/step - loss: 3561370.2500 - mse: 3561370.2500 - mae: 1190.2715 - val_loss: 3810721.0000 - val_mse: 3810721.0000 - val_mae: 1236.0364\n",
      "Epoch 253/500\n",
      "2980/2980 [==============================] - 9s 3ms/step - loss: 3544511.2500 - mse: 3544511.2500 - mae: 1190.0662 - val_loss: 3819337.2500 - val_mse: 3819337.2500 - val_mae: 1276.7389\n",
      "Epoch 254/500\n",
      "2980/2980 [==============================] - 11s 4ms/step - loss: 3555369.7500 - mse: 3555369.7500 - mae: 1189.8741 - val_loss: 3819867.0000 - val_mse: 3819867.0000 - val_mae: 1261.8750\n",
      "Epoch 255/500\n",
      "2980/2980 [==============================] - 13s 4ms/step - loss: 3547243.0000 - mse: 3547243.0000 - mae: 1189.4680 - val_loss: 3794986.7500 - val_mse: 3794986.7500 - val_mae: 1246.1653\n",
      "Epoch 256/500\n",
      "2980/2980 [==============================] - 11s 4ms/step - loss: 3540682.2500 - mse: 3540682.2500 - mae: 1190.1808 - val_loss: 3837924.7500 - val_mse: 3837924.7500 - val_mae: 1248.1019\n",
      "Epoch 257/500\n",
      "2980/2980 [==============================] - 10s 3ms/step - loss: 3500151.7500 - mse: 3500151.7500 - mae: 1188.1089 - val_loss: 3974433.5000 - val_mse: 3974433.5000 - val_mae: 1358.4873\n",
      "Epoch 258/500\n",
      "2980/2980 [==============================] - 8s 3ms/step - loss: 3562949.0000 - mse: 3562949.0000 - mae: 1189.4567 - val_loss: 3813244.5000 - val_mse: 3813244.5000 - val_mae: 1263.9548\n",
      "Epoch 259/500\n",
      "2980/2980 [==============================] - 8s 3ms/step - loss: 3534887.5000 - mse: 3534887.5000 - mae: 1189.1572 - val_loss: 3863145.5000 - val_mse: 3863145.5000 - val_mae: 1245.1006\n",
      "Epoch 260/500\n",
      "2980/2980 [==============================] - 7s 2ms/step - loss: 3541419.0000 - mse: 3541419.0000 - mae: 1190.8917 - val_loss: 3842389.7500 - val_mse: 3842389.7500 - val_mae: 1244.0209\n",
      "Epoch 261/500\n",
      "2980/2980 [==============================] - 9s 3ms/step - loss: 3540690.0000 - mse: 3540690.0000 - mae: 1187.6764 - val_loss: 3798327.0000 - val_mse: 3798327.0000 - val_mae: 1245.4630\n",
      "Epoch 262/500\n",
      "2980/2980 [==============================] - 9s 3ms/step - loss: 3507673.5000 - mse: 3507673.5000 - mae: 1186.4502 - val_loss: 3831230.0000 - val_mse: 3831230.0000 - val_mae: 1257.3872\n",
      "Epoch 263/500\n",
      "2980/2980 [==============================] - 9s 3ms/step - loss: 3533481.0000 - mse: 3533481.0000 - mae: 1187.7975 - val_loss: 3842128.5000 - val_mse: 3842128.5000 - val_mae: 1270.9807\n",
      "Epoch 264/500\n",
      "2980/2980 [==============================] - 9s 3ms/step - loss: 3522556.5000 - mse: 3522556.5000 - mae: 1188.1466 - val_loss: 4211296.5000 - val_mse: 4211296.5000 - val_mae: 1312.6412\n",
      "Epoch 265/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2980/2980 [==============================] - 8s 3ms/step - loss: 3504633.0000 - mse: 3504633.0000 - mae: 1185.9867 - val_loss: 3823308.7500 - val_mse: 3823308.7500 - val_mae: 1305.6689\n",
      "Epoch 266/500\n",
      "2980/2980 [==============================] - 11s 4ms/step - loss: 3518545.0000 - mse: 3518545.0000 - mae: 1187.5066 - val_loss: 4181553.7500 - val_mse: 4181553.7500 - val_mae: 1248.4152\n",
      "Epoch 267/500\n",
      "2980/2980 [==============================] - 10s 3ms/step - loss: 3522271.0000 - mse: 3522271.0000 - mae: 1185.8031 - val_loss: 3880711.7500 - val_mse: 3880711.7500 - val_mae: 1306.1176\n",
      "Epoch 268/500\n",
      "2980/2980 [==============================] - 10s 3ms/step - loss: 3521823.0000 - mse: 3521823.0000 - mae: 1187.8934 - val_loss: 3940493.5000 - val_mse: 3940493.5000 - val_mae: 1232.8627\n",
      "Epoch 269/500\n",
      "2980/2980 [==============================] - 8s 3ms/step - loss: 3499761.2500 - mse: 3499761.2500 - mae: 1185.8798 - val_loss: 3888399.2500 - val_mse: 3888399.2500 - val_mae: 1247.9502\n",
      "Epoch 270/500\n",
      "2980/2980 [==============================] - 9s 3ms/step - loss: 3512541.0000 - mse: 3512541.0000 - mae: 1187.5564 - val_loss: 3986185.5000 - val_mse: 3986185.5000 - val_mae: 1226.8214\n",
      "Epoch 271/500\n",
      "2980/2980 [==============================] - 13s 4ms/step - loss: 3476001.0000 - mse: 3476001.0000 - mae: 1185.9763 - val_loss: 3988867.5000 - val_mse: 3988867.5000 - val_mae: 1272.1318\n",
      "Epoch 272/500\n",
      "2980/2980 [==============================] - 14s 5ms/step - loss: 3460736.0000 - mse: 3460736.0000 - mae: 1184.6608 - val_loss: 3805201.5000 - val_mse: 3805201.5000 - val_mae: 1257.8466\n",
      "Epoch 273/500\n",
      "2980/2980 [==============================] - 15s 5ms/step - loss: 3510900.7500 - mse: 3510900.7500 - mae: 1184.6761 - val_loss: 4063842.5000 - val_mse: 4063842.5000 - val_mae: 1345.9791\n",
      "Epoch 274/500\n",
      "2980/2980 [==============================] - 15s 5ms/step - loss: 3494441.5000 - mse: 3494441.5000 - mae: 1186.8225 - val_loss: 3932030.5000 - val_mse: 3932030.5000 - val_mae: 1331.2369\n",
      "Epoch 275/500\n",
      " 468/2980 [===>..........................] - ETA: 11s - loss: 3642236.7500 - mse: 3642236.7500 - mae: 1193.902"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "init_epochs = 100\n",
    "epochs_now = 500\n",
    "history = model.fit(X_train, y_train, epochs=epochs_now, validation_data=(X_val, y_val), initial_epoch=init_epochs)\n",
    "mse_history += history.history['mse']\n",
    "mae_history += history.history['mae']\n",
    "model.save(f'linear_4/model_{epochs_now}.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "init_epochs = 500\n",
    "epochs_now = 1000\n",
    "history = model.fit(X_train, y_train, epochs=epochs_now, validation_data=(X_val, y_val), initial_epoch=init_epochs)\n",
    "mse_history += history.history['mse']\n",
    "mae_history += history.history['mae']\n",
    "model.save(f'linear_4/model_{epochs_now}.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "init_epochs = 1000\n",
    "epochs_now = 5000\n",
    "history = model.fit(X_train, y_train, epochs=epochs_now, validation_data=(X_val, y_val), initial_epoch=init_epochs)\n",
    "mse_history += history.history['mse']\n",
    "mae_history += history.history['mae']\n",
    "model.save(f'linear_4/model_{epochs_now}.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(mae_history)\n",
    "plt.show()\n",
    "plt.plot(mse_history)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
